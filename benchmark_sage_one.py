import tensorflow as tf
from tensorflow.keras.metrics import BinaryAccuracy
from tensorflow.keras.callbacks import EarlyStopping
from keras.layers import Dense, LSTM, Input
from keras.models import Model
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sage_one import SAGE_ONE
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
import random
import os
import hashlib

seed = 42


def set_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'


set_seeds()


def generate_parity_levels(n_samples=10000, seq_length=10):
    X = np.random.randint(0, 3, size=(n_samples, seq_length))
    # X = np.random.choice([0, 1, 2], size=(n_samples, seq_length))

    # NÃ­vel 1: Paridade simples
    y_lvl1 = (np.sum(X, axis=1) % 2).reshape(-1, 1).astype(np.float32)

    # NÃ­vel 2: Paridade apenas nas posiÃ§Ãµes pares
    y_lvl2 = (np.sum(X[:, ::2], axis=1) % 2).reshape(-1, 1).astype(np.float32)

    # NÃ­vel 3: Soma ponderada nas Ã­mpares com pesos 2^pos
    weights = 2 ** np.arange(1, seq_length, 2)
    weighted_sum = np.sum(X[:, 1::2] * weights, axis=1)
    y_lvl3 = (weighted_sum % 2).reshape(-1, 1).astype(np.float32)

    # NÃ­vel 4: Paridade da soma entre XORs das posiÃ§Ãµes alternadas
    xor_pairs = X[:, :-1:2] ^ X[:, 1::2]
    parity_xor = (np.sum(xor_pairs, axis=1) %
                  2).reshape(-1, 1).astype(np.float32)
    y_lvl4 = parity_xor

    # NÃ­vel 5: XORs + ANDs com pesos simbÃ³licos
    padded = np.concatenate([X, X[:, :2]], axis=1)
    and_triplets = padded[:, :-2] & padded[:, 1:-1] & padded[:, 2:]

    xor_weights = 2 ** np.arange(1, xor_pairs.shape[1] + 1)
    and_weights = np.flip(np.arange(1, and_triplets.shape[1] + 1))

    xor_weighted_sum = np.sum(xor_pairs * xor_weights, axis=1)
    and_weighted_sum = np.sum(and_triplets * and_weights, axis=1)

    combined = (xor_weighted_sum + 3 * and_weighted_sum) % 2
    y_lvl5 = combined.reshape(-1, 1).astype(np.float32)

    # NÃ­vel 6: Hierarquia de XORs (reduÃ§Ã£o tipo Ã¡rvore)
    def hierarchical_xor(seq):
        while seq.shape[1] > 1:
            if seq.shape[1] % 2 != 0:
                seq = np.concatenate(
                    [seq, np.zeros((seq.shape[0], 1), dtype=int)], axis=1)
            seq = seq[:, ::2] ^ seq[:, 1::2]
        return seq

    y_lvl6 = hierarchical_xor(X).astype(np.float32)

    # NÃ­vel 7: LÃ³gica Condicional DinÃ¢mica
    def level7_dynamic_logic(X):
        outputs = []
        for seq in X:
            result = 0
            for i in range(0, len(seq) - 1, 2):
                control = seq[i]
                value = seq[i + 1]
                if control:
                    result ^= value
            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl7 = level7_dynamic_logic(X)

    # ğŸŒªï¸ NÃ­vel 8: Meta-Routing Auto-Referente com ReduÃ§Ã£o Invertida
    def level8_meta_routing(X):
        outputs = []
        for seq in X:
            route = []
            for i in range(0, len(seq) - 2, 3):
                a, b, c = seq[i], seq[i+1], seq[i+2]
                route.append((a & b) ^ c)
            if len(route) == 0:
                route_sum = 0
            else:
                route_sum = route[0]
                for bit in route[1:]:
                    route_sum ^= bit
            result = route_sum ^ (len(route) % 2)
            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl8 = level8_meta_routing(X)

    # âš”ï¸ NÃ­vel 9: Paridade de transiÃ§Ãµes de estados acumulativos (mÃ¡quina de estado simbÃ³lica)

    def level9_state_transitions(X):
        outputs = []
        for seq in X:
            state = 0
            for i in range(len(seq)):
                bit = seq[i]
                if i % 2 == 0:
                    state ^= bit  # transiÃ§Ã£o por XOR
                else:
                    state = (state + bit) % 2  # transiÃ§Ã£o por soma modular
            outputs.append(state)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl9 = level9_state_transitions(X)

    # ğŸš€ NÃ­vel 10: Meta-Paridade com Estado Injetado

    def level10_meta_parity(X):
        results = []
        for seq in X:
            # 1. MÃ¡scara simbÃ³lica: XOR entre pares invertidos
            mask = seq[::-1][::2] ^ seq[::2][:len(seq[::-1][::2])]
            # 2. Aplicar a mÃ¡scara (estende se necessÃ¡rio)
            mask_full = np.resize(mask, len(seq))
            modified = seq ^ mask_full
            # 3. Estado interno: bit central (como "memÃ³ria simbÃ³lica")
            state = modified[len(modified) // 2]
            # 4. Condicional: XOR se estado Ã© 1, caso contrÃ¡rio AND entre blocos
            first_half = modified[:len(modified) // 2]
            second_half = modified[len(modified) // 2:]
            if state == 1:
                op = np.sum(first_half ^ second_half) % 2
            else:
                op = np.sum(first_half & second_half) % 2
            results.append(op)
        return np.array(results).reshape(-1, 1).astype(np.float32)

    y_lvl10 = level10_meta_parity(X)

    # ğŸŒªï¸ NÃ­vel 11: Circuito Condicional Reentrante

    def level11_conditional_reentry(X):
        outputs = []
        for seq in X:
            acc = 0
            for i in range(len(seq) - 3):
                a, b, ctrl1, ctrl2 = seq[i], seq[i + 1], seq[i + 2], seq[i + 3]

                if ctrl1 and not ctrl2:
                    acc ^= a & b  # XOR entre ANDs se ctrl1 ativo
                elif ctrl2 and not ctrl1:
                    acc ^= a | b  # XOR entre ORs se ctrl2 ativo
                elif ctrl1 and ctrl2:
                    acc ^= ~(a ^ b) & 1  # XNOR limitado (bitwise)
                # se nenhum controle ativo, mantÃ©m estado

            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl11 = level11_conditional_reentry(X)

    # ğŸš€ NÃ­vel 12: LÃ³gica Alternada HierÃ¡rquica
    def level12_alternating_logic(X):
        def apply_rule(a, b, rule_id):
            if rule_id == 0:
                return a ^ b        # XOR
            elif rule_id == 1:
                return a & b      # AND
            elif rule_id == 2:
                return a | b      # OR
            elif rule_id == 3:
                return ~(a & b) & 1  # NAND
            elif rule_id == 4:
                return ~(a ^ b) & 1  # XNOR
            else:
                return a ^ b  # fallback

        results = []
        for seq in X:
            result = seq[0]
            for i in range(1, len(seq)):
                rule_id = i % 5  # alterna entre 5 regras
                result = apply_rule(result, seq[i], rule_id)
            results.append(result)
        return np.array(results).reshape(-1, 1).astype(np.float32)

    y_lvl12 = level12_alternating_logic(X)

    def level13_recursive_program(X):
        outputs = []
        for seq in X:
            acc = 0
            for i in range(0, len(seq)-3, 3):
                ctrl1, ctrl2, val = seq[i], seq[i+1], seq[i+2]
                if ctrl1 and ctrl2:
                    acc ^= val  # XOR se dois controles ativos
                elif ctrl1:
                    acc |= val  # OR se sÃ³ um controle ativo
                elif ctrl2:
                    acc &= val  # AND se sÃ³ ctrl2 ativo
                else:
                    acc = ~acc & 1  # NOT se nenhum ativo
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl13 = level13_recursive_program(X)

    # âš”ï¸ NÃ­vel 14: LÃ³gica Condicional Recursiva baseada em CabeÃ§alho BinÃ¡rio

    def level14_recursive_logic(X):
        outputs = []
        for seq in X:
            # Interpreta os 2 primeiros bits como modo de operaÃ§Ã£o
            mode = (seq[0] << 1) | seq[1]  # 00, 01, 10, 11

            if mode == 0:
                result = np.sum(seq[2:6]) % 2
            elif mode == 1:
                result = (seq[2] ^ seq[3]) & (seq[4] | seq[5])
            elif mode == 2:
                result = int(((seq[2] ^ seq[3]) ^ (seq[6] & seq[7])) % 2 == 1)
            else:
                inner = seq[2:6] ^ seq[6:10]
                result = np.sum(inner) % 2

            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl14 = level14_recursive_logic(X)

    # ğŸ§  NÃ­vel 15: Paridade com mÃºltiplos contextos lÃ³gicos cruzados
    def level15_context_switch(X):
        out = []
        for seq in X:
            res = 0
            flip = 0
            for i in range(0, len(seq) - 2, 3):
                a, b, c = seq[i:i+3]
                context = (a << 2) | (b << 1) | c
                if context in [0, 3, 5, 6]:  # contextos lÃ³gicos definidos
                    flip ^= (a & ~b) | (c & b)
                else:
                    flip ^= (a ^ c)
            out.append(flip)
        return np.array(out).reshape(-1, 1).astype(np.float32)

    y_lvl15 = level15_context_switch(X)

    # NÃ­vel 16: Paridade condicional por janelas com rota lÃ³gica de decisÃ£o

    def level16_windowed_conditional(X):
        outputs = []
        for seq in X:
            result = 0
            for i in range(len(seq) - 2):
                window = seq[i:i+3]
                if window[0] == 1 and window[2] == 1:
                    result ^= window[1]  # aplica XOR se bordas sÃ£o 1
                elif window[0] == 0 and window[2] == 0:
                    # inverte e aplica XOR se bordas sÃ£o 0
                    result ^= ~window[1] & 1
                else:
                    result ^= window[0] & window[2]  # aplica AND entre bordas
            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Adiciona ao retorno da funÃ§Ã£o
    y_lvl16 = level16_windowed_conditional(X)

    # ğŸ§  NÃ­vel 17: Paridade com Roteamento Contextual Temporal
    def level17_temporal_context(X):
        outputs = []
        for seq in X:
            context = 0
            memory = 0
            for i in range(len(seq)):
                if i % 2 == 0:
                    context ^= seq[i]
                else:
                    if context:
                        memory += seq[i]
                    else:
                        memory -= seq[i]
            outputs.append(int(memory % 2 == 0))
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl17 = level17_temporal_context(X)

    # âš”ï¸ NÃ­vel 18: MultiplexaÃ§Ã£o simbÃ³lica com controle hierÃ¡rquico

    def level18_multiplexed_logic(X):
        results = []
        for seq in X:
            acc = 0
            for i in range(0, len(seq) - 3, 3):
                ctrl_1 = seq[i]
                ctrl_2 = seq[i + 1]
                val = seq[i + 2]

                # Multiplexador simbÃ³lico com controle hierÃ¡rquico
                if ctrl_1 and not ctrl_2:
                    acc ^= val
                elif ctrl_2 and not ctrl_1:
                    acc &= val
                elif ctrl_1 and ctrl_2:
                    acc |= val
                # senÃ£o ignora
            results.append(acc)
        return np.array(results).reshape(-1, 1).astype(np.float32)

    y_lvl18 = level18_multiplexed_logic(X)

    def level19_meta_conditional(X, block_size=4):
        n_samples, seq_len = X.shape
        outputs = []
        for sample in X:
            result = 0
            for i in range(0, seq_len - block_size, block_size):
                control = sample[i]  # bit de controle do bloco
                data_block = sample[i+1:i+block_size]
                if control:
                    block_result = np.bitwise_and.reduce(data_block)
                else:
                    block_result = np.bitwise_xor.reduce(data_block)
                result ^= block_result  # combina o resultado final com XOR global
            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl19 = level19_meta_conditional(X)

    # âš ï¸ NÃ­vel 20: LÃ³gica simbÃ³lica cruzada com ciclos dinÃ¢micos
    def level20_crossed_cycles(X):
        n = X.shape[1]
        out = []
        for seq in X:
            step1 = []
            acc = 0
            for i in range(n):
                acc += seq[i]
                logic = (seq[i] ^ (acc % 2)) if i % 3 == 0 else (
                    seq[i] & (acc % 2))
                step1.append(logic)
            step2 = []
            for i in range(n):
                prev = step1[i - 1] if i > 0 else step1[-1]
                next_ = step1[(i + 1) % n]
                val = (prev ^ next_) & step1[i]
                step2.append(val)
            final = sum(step2) % 2
            out.append(final)
        return np.array(out).reshape(-1, 1).astype(np.float32)

    y_lvl20 = level20_crossed_cycles(X)

    # âš ï¸ NÃ­vel 21: LÃ³gica Autocondicional com Espelhamento PseudoaleatÃ³rio

    def level21_recursive_logic(X):
        outputs = []
        for seq in X:
            seq = seq.tolist()
            acc = 0
            for i in range(0, len(seq) - 2):
                a = seq[i]
                b = seq[i + 1]
                c = seq[i + 2]

                # Regra condicional: se a Ã© 1, aplica XOR(b, c), senÃ£o aplica XNOR(b, c)
                if a:
                    logic = b ^ c
                else:
                    logic = int(b == c)

                # Espelhamento condicional: se i par, inverte bit
                if i % 2 == 0:
                    logic = 1 - logic

                # Acumula com peso simbÃ³lico dinÃ¢mico (baseado em posiÃ§Ã£o i)
                acc += logic * ((i + 3) % 5 + 1)

            outputs.append(acc % 2)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl21 = level21_recursive_logic(X)

    # ğŸ” NÃ­vel 22: XOR entre subgrupos reversos com deslocamento dinÃ¢mico

    def level22_shifted_xor(X):
        seq_len = X.shape[1]
        shift = (np.sum(X, axis=1) % seq_len).astype(int)
        outputs = []
        for i, seq in enumerate(X):
            s = shift[i]
            rotated = np.roll(seq, s)
            left = rotated[:seq_len // 2]
            right = rotated[seq_len // 2:]
            xor_result = left ^ right[::-1]
            outputs.append(np.sum(xor_result) % 2)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl22 = level22_shifted_xor(X)

    # ğŸ§  NÃ­vel 23: XOR condicional com simulaÃ§Ã£o de memÃ³ria acumulativa

    def level23_memory_xor(X):
        outputs = []
        for seq in X:
            acc = 0
            for i, val in enumerate(seq):
                if i % 3 == 0:
                    acc ^= val
                elif i % 3 == 1:
                    acc ^= (acc & val)
                else:
                    acc ^= (~val & 1)
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl23 = level23_memory_xor(X)

    # ğŸ¤– NÃ­vel 24: SimulaÃ§Ã£o de um autÃ´mato binÃ¡rio (Regra 90-like)

    def level24_automaton(X):
        pad = np.pad(X, ((0, 0), (1, 1)), mode='constant')
        left = pad[:, :-2]
        right = pad[:, 2:]
        center = X
        next_gen = left ^ right
        y = np.sum(next_gen, axis=1) % 2
        return y.reshape(-1, 1).astype(np.float32)

    y_lvl24 = level24_automaton(X)

    # ğŸ“Š NÃ­vel 25: CÃ¡lculo de "peso lÃ³gico" com base em AND/OR

    def level25_logic_weight(X):
        logic_sum = np.sum((X[:, :-1] & X[:, 1:]) |
                           (~X[:, :-1] & ~X[:, 1:]), axis=1)
        y = (logic_sum % 2).astype(np.float32)
        return y.reshape(-1, 1)

    y_lvl25 = level25_logic_weight(X)

    # ğŸ”€ NÃ­vel 26: XOR em grupos de 3 com reversÃµes alternadas

    def level26_triplet_xor(X):
        outputs = []
        for seq in X:
            acc = 0
            for i in range(0, len(seq) - 2, 3):
                a, b, c = seq[i:i+3]
                group = [a, b, c][::-1] if i % 2 == 0 else [a, b, c]
                acc ^= group[0] ^ group[1] ^ group[2]
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl26 = level26_triplet_xor(X)

    # ğŸ§© NÃ­vel 27: OperaÃ§Ã£o customizada baseada em padrÃµes alternados

    def level27_pattern_logic(X):
        outputs = []
        for seq in X:
            acc = 1
            for i in range(1, len(seq)):
                if seq[i - 1] == 1 and seq[i] == 0:
                    acc ^= 1
                elif seq[i - 1] == 0 and seq[i] == 1:
                    acc &= 1
                else:
                    acc |= 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl27 = level27_pattern_logic(X)

    # ğŸ§  NÃ­vel 28: CondiÃ§Ãµes aninhadas com XOR e OR simulando controle de fluxo

    def level28_nested_conditions(X):
        outputs = []
        for seq in X:
            acc = 0
            for i in range(len(seq)):
                if seq[i]:
                    acc ^= (seq[i - 1] if i > 0 else 0)
                else:
                    acc |= (seq[i - 2] if i > 1 else 0)
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl28 = level28_nested_conditions(X)

    # âš™ï¸ NÃ­vel 29: Combina lÃ³gica e posiÃ§Ã£o (influÃªncia indexada)

    def level29_indexed_logic(X):
        outputs = []
        for seq in X:
            acc = 1
            for i, val in enumerate(seq):
                if i % 2 == 0:
                    acc ^= val
                else:
                    acc &= val
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl29 = level29_indexed_logic(X)

    # ğŸ§ ğŸ’¥ NÃ­vel 30: CombinaÃ§Ã£o final â€“ lÃ³gica cruzada com simulaÃ§Ã£o de meta-raciocÃ­nio

    def level30_meta_reasoning(X):
        xor_pairs = X[:, :-1:2] ^ X[:, 1::2]
        and_blocks = X[:, ::2] & X[:, 1::2]
        score = (np.sum(xor_pairs, axis=1) * 2 +
                 np.sum(and_blocks, axis=1)) % 2
        return score.reshape(-1, 1).astype(np.float32)

    y_lvl30 = level30_meta_reasoning(X)

    # ğŸ§¾ NÃ­vel 31: MÃ¡quina de Turing simbÃ³lica (leitura com regra de estado binÃ¡rio) AGI Simulada ~

    def level31_turing_machine(X):
        outputs = []
        for seq in X:
            state = 0
            head = 0
            tape = seq.copy()
            for _ in range(3):  # 3 "passos" na fita
                if tape[head] == 1:
                    state ^= 1
                    tape[head] = 0
                    head = (head + 1) % len(tape)
                else:
                    state |= 1
                    tape[head] = 1
                    head = (head - 1) % len(tape)
            outputs.append(state)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl31 = level31_turing_machine(X)

    # ğŸ§ ğŸ”¥ NÃ­vel 32: MÃ¡quina de Turing com Fita e Estado interno

    def level32_turing_machine(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())  # fita binÃ¡ria
            head = len(tape) // 2    # comeÃ§a no meio da fita
            state = 0                # estado inicial

            for _ in range(10):  # nÃºmero fixo de ciclos
                symbol = tape[head]

                if state == 0:
                    if symbol == 0:
                        tape[head] = 1
                        head = max(0, head - 1)
                        state = 1
                    else:
                        tape[head] = 0
                        head = min(len(tape) - 1, head + 1)
                        state = 2

                elif state == 1:
                    if symbol == 0:
                        head = min(len(tape) - 1, head + 1)
                        state = 2
                    else:
                        tape[head] = 1
                        head = max(0, head - 1)
                        state = 0

                elif state == 2:
                    if symbol == 1:
                        tape[head] = 0
                        state = 1
                    else:
                        head = max(0, head - 1)
                        state = 0

            output = sum(tape) % 2  # paridade final da fita apÃ³s modificaÃ§Ãµes
            outputs.append(output)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl32 = level32_turing_machine(X)

    # ğŸ—ï¸ NÃ­vel 33: SimulaÃ§Ã£o de mÃ¡quina de Turing com empilhamento lÃ³gico reverso

    def level33_stack_sim(X):
        outputs = []
        for seq in X:
            stack = []
            for i, bit in enumerate(seq):
                if i % 2 == 0:
                    stack.append(bit)
                else:
                    if stack:
                        top = stack.pop()
                        bit = bit ^ top
                    else:
                        bit = bit
            result = bit if len(stack) % 2 == 0 else bit ^ 1
            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl33 = level33_stack_sim(X)

    # ğŸ§ âš™ï¸ NÃ­vel 34: MÃ¡quina de Turing simbÃ³lica minimalista (com estados e escrita)

    def level34_turing_machine(X):
        outputs = []

        for seq in X:
            tape = list(seq.copy())
            state = 0  # ComeÃ§a no estado 0
            head = len(tape) // 2  # ComeÃ§a no meio da fita

            # Define a tabela de transiÃ§Ã£o: (estado_atual, valor_lido) -> (novo_valor, prÃ³ximo_estado, movimento)
            transitions = {
                (0, 0): (1, 1, 1),
                (0, 1): (0, 0, -1),
                (1, 0): (1, 0, -1),
                (1, 1): (0, 1, 1),
            }

            steps = len(seq) * 2  # NÃºmero de passos de simulaÃ§Ã£o
            for _ in range(steps):
                symbol = tape[head]
                key = (state, symbol)
                if key in transitions:
                    new_val, next_state, move = transitions[key]
                    tape[head] = new_val
                    state = next_state
                    head += move
                    # limita dentro da fita
                    head = max(0, min(len(tape) - 1, head))

            # SaÃ­da: paridade da fita modificada (simbolizando computaÃ§Ã£o da mÃ¡quina)
            result = sum(tape) % 2
            outputs.append(result)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl34 = level34_turing_machine(X)

    # ğŸ§ ğŸŒ€ NÃ­vel 35: SimulaÃ§Ã£o de MÃ¡quina de Turing com estados, fita e controle condicional

    def level35_turing_sim(X):
        outputs = []
        for seq in X:
            state = 0
            head = 0
            tape = seq.copy().tolist()
            steps = len(tape) * 2

            for _ in range(steps):
                symbol = tape[head] if 0 <= head < len(tape) else 0

                # TransiÃ§Ãµes de estado baseadas no sÃ­mbolo
                if state == 0:
                    if symbol == 1:
                        state = 1
                        tape[head] = 0
                        head += 1
                    else:
                        head += 1
                elif state == 1:
                    if symbol == 0:
                        state = 2
                        tape[head] = 1
                        head -= 1
                    else:
                        head += 1
                elif state == 2:
                    if symbol == 1:
                        state = 0
                        head += 1
                    else:
                        tape[head] = 1
                        head -= 1

                if head < 0 or head >= len(tape):
                    break

            parity = sum(tape) % 2
            outputs.append(parity)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl35 = level35_turing_sim(X)

    # ğŸ§ âš™ï¸ NÃ­vel 36: MÃ¡quina de Turing com cabeÃ§a de leitura simbÃ³lica

    def level36_turing_machine(X):
        outputs = []
        for seq in X:
            state = 0
            for i in range(len(seq)):
                if state == 0:
                    state = 1 if seq[i] == 1 else 0
                elif state == 1:
                    state = 2 if seq[i] == 0 else 0
                elif state == 2:
                    state = 3 if seq[i] == 1 else 1
                elif state == 3:
                    state = 0 if seq[i] == 1 else 2
            # saÃ­da simbÃ³lica com base no estado final
            outputs.append(state % 2)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl36 = level36_turing_machine(X)

    # ğŸ§µ NÃ­vel 37: MÃ¡quina de Turing binÃ¡ria com fita, transiÃ§Ãµes e estado finito

    def level37_turing_machine(X):
        outputs = []
        for seq in X:
            state = 0
            head_pos = len(seq) // 2  # comeÃ§a no meio
            tape = seq.copy()
            for _ in range(len(seq) * 2):  # nÃºmero de passos
                symbol = tape[head_pos]
                # TransiÃ§Ãµes com base no estado e sÃ­mbolo lido
                if state == 0 and symbol == 0:
                    tape[head_pos] = 1
                    state = 1
                    head_pos += 1
                elif state == 0 and symbol == 1:
                    tape[head_pos] = 0
                    state = 0
                    head_pos -= 1
                elif state == 1 and symbol == 0:
                    tape[head_pos] = 1
                    state = 0
                    head_pos -= 1
                elif state == 1 and symbol == 1:
                    tape[head_pos] = 1
                    state = 1
                    head_pos += 1
                head_pos = max(0, min(head_pos, len(seq) - 1))  # limita a fita
            # saÃ­da final Ã© o valor atual da cabeÃ§a
            outputs.append(tape[head_pos])
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl37 = level37_turing_machine(X)

    # ğŸ§¾ NÃ­vel 38: SimulaÃ§Ã£o de mÃ¡quina de Turing binÃ¡ria com uma Ãºnica regra de transiÃ§Ã£o

    def level38_turing(X):
        outputs = []
        for seq in X:
            state = 0
            head = len(seq) // 2
            tape = list(seq.copy())
            for _ in range(10):  # atÃ© 10 passos de execuÃ§Ã£o
                read = tape[head]
                if state == 0 and read == 1:
                    tape[head] = 0
                    head = max(0, head - 1)
                    state = 1
                elif state == 1 and read == 0:
                    tape[head] = 1
                    head = min(len(seq) - 1, head + 1)
                    state = 0
                else:
                    break
            outputs.append(tape[head])
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl38 = level38_turing(X)

    # ğŸ§ âš™ï¸ NÃ­vel 39: MÃ¡quina de Turing SimbÃ³lica com CabeÃ§ote Deslizante = AGI Lite

    def level39_turing_machine(X):
        outputs = []
        for seq in X:
            head = 0
            tape = seq.copy()
            acc = 0

            for _ in range(len(seq)):
                curr = tape[head]

                if curr == 1:
                    acc ^= 1
                    head = (head + 2) % len(seq)
                else:
                    acc &= 1
                    head = (head - 1) % len(seq)

            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl39 = level39_turing_machine(X)

    # ğŸ§ ğŸ” NÃ­vel 40: MÃ¡quina de Turing LÃ³gica com CabeÃ§a SimbÃ³lica

    def level40_turing_head(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            head = 0
            state = 1

            for _ in range(len(tape)):
                symbol = tape[head]
                if state == 1:
                    if symbol == 0:
                        tape[head] = 1
                        head = (head + 1) % len(tape)
                        state = 2
                    else:
                        tape[head] = 0
                        head = (head - 1) % len(tape)
                        state = 3
                elif state == 2:
                    tape[head] ^= 1
                    head = (head + 2) % len(tape)
                    state = 1
                elif state == 3:
                    tape[head] |= 1
                    head = (head + 1) % len(tape)
                    state = 2

            # A saÃ­da Ã© a soma da fita final, paridade da soma e posiÃ§Ã£o final da cabeÃ§a
            acc = (sum(tape) + head) % 2
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl40 = level40_turing_head(X)

    # âš™ï¸ğŸ§  NÃ­vel 41 - Dupla CabeÃ§a de Turing com Feedback Cruzado

    def level41_double_heads(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            h1, h2 = 0, len(seq) // 2
            s1, s2 = 1, 1

            for _ in range(len(seq)):
                v1, v2 = tape[h1], tape[h2]

                if s1 == 1:
                    tape[h1] ^= v2
                    h1 = (h1 + 1) % len(seq)
                    s1 = 2
                else:
                    tape[h1] |= v1
                    h1 = (h1 - 1) % len(seq)
                    s1 = 1

                if s2 == 1:
                    tape[h2] &= v1
                    h2 = (h2 + 2) % len(seq)
                    s2 = 2
                else:
                    tape[h2] ^= 1
                    h2 = (h2 - 2) % len(seq)
                    s2 = 1

            acc = (sum(tape) + h1 + h2 + s1 + s2) % 2
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl41 = level41_double_heads(X)

    # ğŸ§ ğŸ‘‘ NÃ­vel 42 - MÃ¡quina de Turing SimbÃ³lica com 3 CabeÃ§as, Estados DinÃ¢micos e Simetria Espelhada

    def level42_triple_heads_symmetry(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            h1, h2, h3 = 0, n // 3, 2 * n // 3
            s1, s2, s3 = 0, 1, 2

            for _ in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # Atualiza fita com lÃ³gica cruzada
                if s1 == 0:
                    tape[h1] ^= v2 & v3
                    h1 = (h1 + 1) % n
                    s1 = 1
                else:
                    tape[h1] = (v1 | v2) ^ v3
                    h1 = (h1 - 1) % n
                    s1 = 0

                if s2 == 1:
                    tape[h2] ^= v1
                    h2 = (h2 + 2) % n
                    s2 = 2
                else:
                    tape[h2] &= v3
                    h2 = (h2 - 2) % n
                    s2 = 1

                if s3 == 2:
                    tape[h3] = (~v2) & 1
                    h3 = (h3 + 3) % n
                    s3 = 0
                else:
                    tape[h3] |= v1 ^ v2
                    h3 = (h3 - 1) % n
                    s3 = 2

            # Espelhamento da fita e cÃ¡lculo de padrÃ£o simÃ©trico
            mirrored = tape[::-1]
            pattern_score = sum(1 for a, b in zip(tape, mirrored) if a == b)

            acc = (pattern_score + h1 + h2 + h3 + s1 + s2 + s3) % 2
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl42 = level42_triple_heads_symmetry(X)

    # ğŸ§ ğŸŒ€ NÃ­vel 43 â€“ MÃ¡quina de Turing SimbÃ³lica com ReflexÃ£o Temporal, RotaÃ§Ã£o Circular e Paridade Cruzada

    def level43_time_reflection_parity(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            h1, h2 = 0, n // 2
            s1, s2 = 0, 1
            history = []

            for step in range(n):
                v1, v2 = tape[h1], tape[h2]

                # HistÃ³ricos das posiÃ§Ãµes e estados
                history.append((h1, h2, s1, s2))

                # CabeÃ§a 1 â€“ lÃ³gica reflexiva condicional
                if s1 == 0:
                    tape[h1] = v1 ^ v2
                    h1 = (h1 + 1) % n
                    s1 = 1
                else:
                    tape[h1] = v1 & (~v2 & 1)
                    h1 = (h1 - 1) % n
                    s1 = 0

                # CabeÃ§a 2 â€“ lÃ³gica cruzada + rotaÃ§Ã£o
                if s2 == 1:
                    tape[h2] = (v2 | v1) ^ 1
                    h2 = (h2 + 2) % n
                    s2 = 2
                else:
                    tape[h2] ^= (h1 % 2)
                    h2 = (h2 - 2) % n
                    s2 = 1

            # ğŸ” ReflexÃ£o Temporal: volta parcial no histÃ³rico
            for h1, h2, s1, s2 in reversed(history[:n//2]):
                tape[h1] ^= 1
                tape[h2] |= s1 ^ s2

            # ğŸ”„ RotaÃ§Ã£o circular final
            rotated = tape[n//2:] + tape[:n//2]

            # ğŸ§® Paridade cruzada entre primeira e segunda metade
            half1, half2 = rotated[:n//2], rotated[n//2:]
            acc = sum([a ^ b for a, b in zip(half1, half2)]) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl43 = level43_time_reflection_parity(X)

    # ğŸ§ ğŸ’¾ NÃ­vel 44 â€“ MÃ¡quina SimbÃ³lica Auto-Transformadora com Escrita de Regras DinÃ¢micas

    def level44_self_modifying_machine(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            rules = {}  # regras de transiÃ§Ã£o dinÃ¢micas
            head = 0
            state = 1

            for _ in range(n):
                symbol = tape[head]
                key = (state, symbol)

                # Cria uma nova regra se ainda nÃ£o existir
                if key not in rules:
                    rules[key] = (1 - symbol, (head + symbol + state) %
                                  n, (state + symbol + 1) % 4)

                write_val, move_to, new_state = rules[key]

                tape[head] = write_val
                head = move_to
                state = new_state

                # Auto-transformaÃ§Ã£o simbÃ³lica de regras (meta-escrita)
                if len(rules) > 3:
                    oldest_key = list(rules.keys())[0]
                    rules[oldest_key] = (
                        rules[oldest_key][0] ^ 1,
                        (rules[oldest_key][1] + 1) % n,
                        (rules[oldest_key][2] + 1) % 5,
                    )

            checksum = (sum(tape) + head + state + len(rules)) % 2
            outputs.append(checksum)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl44 = level44_self_modifying_machine(X)

    # âš™ï¸ğŸ§  NÃ­vel 45 - Meta-Turing com Contexto Persistente

    def level45_meta_turing_context(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # TrÃªs cabeÃ§as, cada uma com seu prÃ³prio estado
            h1, h2, h3 = 0, n // 3, 2 * n // 3
            s1, s2, s3 = 0, 1, 2

            # MemÃ³ria simbÃ³lica persistente entre iteraÃ§Ãµes
            context = 0

            for _ in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # LÃ³gica cruzada com mutaÃ§Ãµes contextuais
                if s1 == 0:
                    tape[h1] = v1 ^ (v2 & context)
                    context ^= v3
                    h1 = (h1 + 1) % n
                    s1 = 1
                else:
                    tape[h1] = (~(v1 | context)) & 1
                    h1 = (h1 - 1) % n
                    s1 = 0

                if s2 == 1:
                    tape[h2] ^= (v1 | v3)
                    context |= v2
                    h2 = (h2 + 2) % n
                    s2 = 2
                else:
                    tape[h2] = (v2 & context) ^ v1
                    h2 = (h2 - 2) % n
                    s2 = 1

                if s3 == 2:
                    tape[h3] = (v3 ^ context) & 1
                    context ^= (v1 & v2)
                    h3 = (h3 + 3) % n
                    s3 = 0
                else:
                    tape[h3] = (v1 | v2 | v3 | context) % 2
                    h3 = (h3 - 1) % n
                    s3 = 2

            # Final: paridade do padrÃ£o mais score da simetria da fita
            mirrored = tape[::-1]
            sym_score = sum(1 for a, b in zip(tape, mirrored) if a == b)
            acc = (sum(tape) + h1 + h2 + h3 + context + sym_score) % 2

            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl45 = level45_meta_turing_context(X)

    # NÃ­vel 46 â€“ â€œMÃ¡quina de Estados HierÃ¡rquicos com Loop de ConsciÃªnciaâ€ ğŸ§ ğŸŒ€

    def level46_conscious_hierarchy(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # InicializaÃ§Ã£o de trÃªs cabeÃ§as independentes
            h1, h2, h3 = 0, n // 3, 2 * n // 3
            s1, s2, s3 = 1, 2, 3  # Estados simbÃ³licos iniciais
            last_states = [1, 2, 3]  # MemÃ³ria reflexiva de estados anteriores

            for _ in range(n):

                v1, v2, v3 = tape[h1], tape[h2], tape[h3]
                ref = last_states[_ % 3]  # estado anterior mais distante

                # Camada LÃ³gica 1 - processamento direto
                if s1 % 2 == 1:
                    tape[h1] ^= (v2 | v3)
                    h1 = (h1 + 1) % n
                    s1 = (s1 + ref) % 4
                else:
                    tape[h1] = (v1 & ~v2) | v3
                    h1 = (h1 - 1) % n
                    s1 = (s1 + 2) % 5

                # Camada LÃ³gica 2 - cruzamento dinÃ¢mico
                if s2 in [2, 3]:
                    tape[h2] ^= (v1 & v3)
                    h2 = (h2 + 2) % n
                    s2 = (s2 + ref) % 4
                else:
                    tape[h2] |= (v2 ^ v1)
                    h2 = (h2 - 2) % n
                    s2 = (s2 + 1) % 5

                # Camada LÃ³gica 3 - metaaprendizado (autoajuste simbÃ³lico)
                if s3 == 3:
                    tape[h3] = (~v1 & v2) ^ ref
                    h3 = (h3 + 3) % n
                    s3 = (s3 + v3 + 1) % 4
                else:
                    tape[h3] |= (v3 ^ ref)
                    h3 = (h3 - 1) % n
                    s3 = (s3 + v2) % 5

                # Atualiza memÃ³ria reflexiva
                last_states = [s1, s2, s3]

            # MÃ³dulo final: loop de consciÃªncia (espelho do inÃ­cio + estado)
            mirrored = tape[::-1]
            sim = sum(1 for a, b in zip(tape, mirrored) if a == b)

            # SaÃ­da simbÃ³lica composta
            acc = (sim + sum(tape) + s1 + s2 + s3 + h1 + h2 + h3) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl46 = level46_conscious_hierarchy(X)

    # ğŸ§ ğŸ•°ï¸ NÃ­vel 47 - ConsciÃªncia Temporal Bidirecional com ConsistÃªncia HistÃ³rica

    def level47_conscious_turing(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            history = []
            forward_head, backward_head = 0, n - 1
            state = 0
            consistent = True

            for t in range(n // 2):
                # Forward step
                symbol_fwd = tape[forward_head]
                history.append((forward_head, symbol_fwd, state))
                state = (state + symbol_fwd + forward_head) % 4
                tape[forward_head] ^= (state % 2)
                forward_head = (forward_head + 1) % n

                # Backward step (simultÃ¢neo)
                symbol_bwd = tape[backward_head]
                expected_state = (state + symbol_bwd + backward_head) % 4
                if abs(expected_state - state) > 1:
                    consistent = False
                state = expected_state
                tape[backward_head] ^= (state % 2)
                backward_head = (backward_head - 1) % n

            # QuantizaÃ§Ã£o de estados finais
            final_state = (sum(tape) + state +
                           forward_head + backward_head) % 8
            acc = int(consistent and (final_state % 2 == 0))
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Para gerar o y:
    y_lvl47 = level47_conscious_turing(X)

    # ğŸ§ ğŸŒ€ NÃ­vel 48 â€” Espelho Recursivo com InterferÃªncia de Estados

    def level48_recursive_mirror_interference(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            memory = [0] * n
            influence = 0

            for i in range(n):
                mirror_idx = n - i - 1
                if tape[i] == tape[mirror_idx]:
                    influence += 1
                    memory[i] = 1
                else:
                    memory[i] = memory[i - 1] if i > 0 else 0

                # InterferÃªncia simbÃ³lica: padrÃµes anteriores mudam a interpretaÃ§Ã£o atual
                if i % 3 == 0 and i > 1:
                    memory[i] ^= memory[i - 2]

            # A saÃ­da depende da soma da memÃ³ria simbÃ³lica e do padrÃ£o de interferÃªncia
            acc = (sum(memory) + influence + tape[-1]) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl48 = level48_recursive_mirror_interference(X)

    # ğŸ”„ğŸ§  NÃ­vel 49: Paridade Temporal com ConsistÃªncia Reversa e Estados HistÃ³ricos Paralelos

    def level49_temporal_reversal(X):
        outputs = []
        for seq in X:
            forward_state = 0
            reverse_state = 1
            mirror_seq = seq[::-1]
            history_forward = []
            history_reverse = []

            # Caminho normal (esquerda â†’ direita)
            for i, bit in enumerate(seq):
                forward_state ^= (bit + i) % 2
                history_forward.append(forward_state)

            # Caminho reverso (direita â†’ esquerda)
            for i, bit in enumerate(mirror_seq):
                reverse_state ^= (bit * (i % 3)) % 2
                history_reverse.append(reverse_state)

            # CombinaÃ§Ã£o simbÃ³lica cruzada entre os dois histÃ³ricos
            combined = []
            for a, b in zip(history_forward, history_reverse[::-1]):
                combined.append((a ^ b) & 1)

            # A saÃ­da depende da paridade da soma dos estados cruzados e consistÃªncia do inÃ­cio e fim
            parity = sum(combined) % 2
            consistent = int(seq[0] == seq[-1])
            acc = (parity + consistent) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Uso:
    y_lvl49 = level49_temporal_reversal(X)

    # ğŸ§ ğŸª NÃ­vel 50 â€” MÃ¡quina de AutorreflexÃ£o SimbÃ³lica com BifurcaÃ§Ã£o de ConsciÃªncia

    def level50_symbolic_self_reflection(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Dois "eus" simbÃ³licos com cabeÃ§as, estados e memÃ³rias independentes
            heads = [0, n // 2]
            states = [1, 1]
            memories = [[0] * n, [0] * n]

            for _ in range(n):
                for i in range(2):  # cada "eu"
                    h = heads[i]
                    s = states[i]
                    v = tape[h]

                    # Simula transformaÃ§Ã£o simbÃ³lica do estado interno
                    if s == 1:
                        tape[h] ^= 1
                        memories[i][h] = (memories[i][h] + 1) % 2
                        heads[i] = (h + 1) % n
                        states[i] = 2
                    else:
                        tape[h] ^= memories[i][h]
                        memories[i][h] = (memories[i][h] + tape[h]) % 2
                        heads[i] = (h - 1) % n
                        states[i] = 1

            # ReflexÃ£o cruzada: comparam inconsistÃªncias entre os dois mundos
            diffs = sum(1 for a, b in zip(memories[0], memories[1]) if a != b)
            consistency = sum(1 for a, b in zip(tape, tape[::-1]) if a == b)

            # SaÃ­da codifica reflexo simbÃ³lico entre os dois eus e o universo
            acc = (diffs + consistency + sum(heads) + sum(states)) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl50 = level50_symbolic_self_reflection(X)

    # ğŸ§ ğŸ”® NÃ­vel 51 â€“ MÃ¡quina de SimulaÃ§Ã£o de Teoria da Mente com ProjeÃ§Ã£o Contrafactual

    def level51_theory_of_mind(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # TrÃªs cabeÃ§as simulam "mentes"
            h1, h2, h3 = 0, n // 3, 2 * n // 3
            s1, s2, s3 = 1, 1, 1

            for _ in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # CabeÃ§a 1 simula o que a 2 pensaria da 3 no passado
                mind2_about3 = (v3 ^ s2) & 1
                h1 = (h1 + mind2_about3 + 1) % n
                s1 = (s1 + mind2_about3) % 3

                # CabeÃ§a 2 simula o que a 3 pensa da 1
                mind3_about1 = ((v1 | s3) ^ 1) & 1
                h2 = (h2 + mind3_about1 + 2) % n
                s2 = (s2 + mind3_about1) % 3

                # CabeÃ§a 3 simula o que a 1 pensa da 2, e projeta contrafactualmente (inverso do que seria)
                mind1_about2 = (~(v2 ^ s1)) & 1
                h3 = (h3 - mind1_about2 - 1) % n
                s3 = (s3 + mind1_about2) % 3

                # Atualiza a fita com a intersecÃ§Ã£o das percepÃ§Ãµes simuladas
                tape[h1] ^= mind2_about3
                tape[h2] ^= mind3_about1
                tape[h3] ^= mind1_about2

            # A saÃ­da depende do padrÃ£o de consistÃªncia entre as projeÃ§Ãµes mentais cruzadas
            projection_score = (s1 + s2 + s3 + h1 + h2 + h3 + sum(tape)) % 2
            outputs.append(projection_score)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # AplicaÃ§Ã£o
    y_lvl51 = level51_theory_of_mind(X)

    # ğŸ§ ğŸŒŒ NÃ­vel 52 - MÃ¡quina QuÃ¢ntica de Estados Paralelos com MÃºltiplas Realidades

    def level52_quantum_realities(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            heads = [0, len(seq)//3, 2*len(seq)//3]
            states = [1, 2, 3]
            histories = [[], [], []]

            for _ in range(len(tape)):
                for i in range(3):
                    pos = heads[i]
                    val = tape[pos]
                    state = states[i]

                    # SimulaÃ§Ã£o de realidades paralelas
                    if state == 1:
                        tape[pos] ^= 1
                        heads[i] = (pos + 1) % len(tape)
                        states[i] = 2
                    elif state == 2:
                        tape[pos] = tape[pos] ^ ((val << 1) | 1) % 2
                        heads[i] = (pos + 2) % len(tape)
                        states[i] = 3
                    elif state == 3:
                        tape[pos] = (tape[pos] + sum(tape) + i) % 2
                        heads[i] = (pos - 1) % len(tape)
                        states[i] = 1

                    histories[i].append(tape[pos])

            # A saÃ­da depende da coerÃªncia entre realidades (histÃ³ricos convergentes)
            agreement = sum(1 for a, b, c in zip(*histories) if a == b == c)
            acc = (agreement + sum(heads) + sum(states)) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl52 = level52_quantum_realities(X)

    # ğŸŒ€ğŸ§  NÃ­vel 53 - MÃ¡quina Temporal com Causalidade Cruzada e Espelhos HistÃ³ricos

    def level53_temporal_causal_mirror(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            mirror_tape = tape[::-1]
            acc = 0

            for i in range(n):
                t = tape[i]
                m = mirror_tape[i]
                forward = tape[(i+1) % n]
                backward = tape[(i-1) % n]

                # Causalidade temporal cruzada
                logic = (t & forward) ^ (m | backward)
                logic = (logic + acc) % 2

                # Espelho histÃ³rico (simetria com peso decrescente)
                weight = 1.0 - abs(i - n//2) / (n//2)
                acc += int(logic * weight)

            # Paridade da soma acumulada simbÃ³lica
            out = acc % 2
            outputs.append(out)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl53 = level53_temporal_causal_mirror(X)

    # ğŸ”¥ğŸ§  NÃ­vel 54 â€“ MÃ¡quina de ConsciÃªncia Temporal Bidirecional com ConsistÃªncia HistÃ³rica e Estados Quantizados

    def level54_symbolic_consciousness(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as bidirecionais com histÃ³rico simbÃ³lico cruzado
            h1, h2 = 0, n - 1
            s1, s2 = 1, 2
            history = []

            for t in range(n):
                v1, v2 = tape[h1], tape[h2]

                # Estado s1 com lÃ³gica ilusÃ³ria (operaÃ§Ãµes reversÃ­veis)
                if s1 == 1:
                    tape[h1] ^= v2
                    s1 = 2
                else:
                    tape[h1] = (~v1) & 1
                    s1 = 1
                h1 = (h1 + 1) % n

                # Estado s2 com mutaÃ§Ãµes cÃ­clicas e resgate histÃ³rico
                if s2 == 2:
                    tape[h2] |= v1
                    s2 = 3
                elif s2 == 3:
                    tape[h2] ^= v2
                    s2 = 1
                h2 = (h2 - 1) % n

                # Armazena a simetria momentÃ¢nea
                pattern = int(v1 == v2)
                history.append(pattern)

            # ConsistÃªncia histÃ³rica simbÃ³lica cruzada
            symmetry_score = sum(history[i] == history[-1 - i]
                                 for i in range(n // 2))
            state_signature = (s1 * 3 + s2) % 5
            final_sum = sum(tape) + symmetry_score + state_signature

            acc = final_sum % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl54 = level54_symbolic_consciousness(X)

    # ğŸ§ â³ NÃ­vel 55 â€“ Meta-temporal com ruÃ­do adaptativo e eventos ocultos

    def level55_meta_temporal_hidden_noise(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            hidden_state = 1
            # ruÃ­do adaptativo baseado na prÃ³pria entrada
            noise_gate = (sum(tape[:3]) % 2)
            ghost_memory = [0] * n  # memÃ³ria fantasma invisÃ­vel

            for i in range(n):
                symbol = tape[i]
                past = tape[i - 1] if i > 0 else 0
                future = tape[i + 1] if i < n - 1 else 0

                # Evento oculto simbÃ³lico
                if (i + hidden_state) % 3 == 0:
                    ghost_memory[i] = 1
                    hidden_state = (hidden_state + symbol + past + future) % 4
                else:
                    ghost_memory[i] = 0
                    hidden_state = (hidden_state + 1) % 4

                # RuÃ­do adaptativo: muda bits irrelevantes, mas que confundem
                if (i % 2 == noise_gate):
                    tape[i] ^= (past & ~future) & 1

            # Resultado depende da consistÃªncia entre a fita e a memÃ³ria oculta
            aligned = sum(1 for a, b in zip(tape, ghost_memory) if a == b)
            acc = (aligned + hidden_state + noise_gate + sum(ghost_memory)) % 2
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl55 = level55_meta_temporal_hidden_noise(X)

    # NÃ­vel 56 â€“ Metaespelhamento Causal Recursivo

    def level56_meta_mirror_causal(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # TrÃªs cabeÃ§as com deslocamentos espelhados
            h1, h2, h3 = 0, n // 2, n - 1
            s1, s2, s3 = 0, 1, 2

            history = []

            for _ in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # Regras causais com simetria condicional
                if s1 == 0:
                    tape[h1] ^= v2 & (~v3 & 1)
                    s1 = 1
                else:
                    tape[h1] = (v1 | v3) ^ v2
                    s1 = 0
                h1 = (h1 + 1) % n

                if s2 == 1:
                    tape[h2] = (v2 & v1) ^ (~v3 & 1)
                    s2 = 2
                else:
                    tape[h2] ^= (v3 | v1)
                    s2 = 1
                h2 = (h2 - 1) % n

                if s3 == 2:
                    tape[h3] = v1 ^ v2 ^ v3
                    s3 = 0
                else:
                    tape[h3] = (v1 & v2) | (~v3 & 1)
                    s3 = 2
                h3 = (h3 + 2) % n

                # Armazena histÃ³rico para simular reversÃ£o posterior
                history.append(tuple(tape))

            # Metaespelhamento: compara reversÃ£o simulada do histÃ³rico
            reversed_check = True
            for i in range(n // 2):
                left = history[i]
                right = history[-i-1][::-1]
                if left != right:
                    reversed_check = False
                    break

            acc = 1 if reversed_check else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl56 = level56_meta_mirror_causal(X)

    # Nivel 57 - MetaLÃ³gica Temporal: paridade dos 4 primeiros âŠ• paridade cruzada dos 4 Ãºltimos

    def level57_meta_causal_dupla_paridade(X):
        outputs = []
        for seq in X:
            seq = seq.astype(int)
            n = len(seq)
            metade = n // 2

            A = list(seq[:metade])
            B = list(seq[metade:])

            # CabeÃ§as de leitura para A e B
            ha, hb = 0, len(B) - 1
            sa, sb = 0, 0

            history_a, history_b = [], []

            for _ in range(metade):
                va = A[ha]
                vb = B[hb]

                # Regras causais diferentes para cada metade
                if sa == 0:
                    A[ha] ^= (va & 1)
                    sa = 1
                else:
                    A[ha] = (va ^ ha) % 2
                    sa = 0
                ha = (ha + 1) % metade

                if sb == 0:
                    B[hb] = (vb | (hb % 2)) ^ 1
                    sb = 1
                else:
                    B[hb] ^= (vb & (hb % 2))
                    sb = 0
                hb = (hb - 1) % metade

                history_a.append(A.copy())
                history_b.append(B.copy())

            # Paridade simples de A
            par_A = sum(A) % 2

            # Paridade cruzada de B (posiÃ§Ã£o par âŠ• posiÃ§Ã£o Ã­mpar)
            cruzada = 0
            for i in range(0, len(B)-1, 2):
                cruzada ^= B[i] ^ B[i+1]

            acc = par_A ^ cruzada
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Exemplo de uso:
    y_lvl57 = level57_meta_causal_dupla_paridade(X)

    # ConsciÃªncia SimbÃ³lica Temporal com MemÃ³ria e Simetria Cruzada.

    def level58_consciencia_simbolica_temporal(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            heads = [0, n//3, 2*n//3]
            states = [0, 1, 2]
            mem = []

            consistent_history = True

            for step in range(n):
                vals = [tape[h] for h in heads]
                combined = sum(vals) % 2

                # Regras cruzadas com memÃ³ria interna e consistÃªncia temporal
                if states[0] == 0:
                    tape[heads[0]] ^= vals[1]
                    states[0] = 1
                else:
                    tape[heads[0]] = vals[2] ^ combined
                    states[0] = 0
                heads[0] = (heads[0] + 1) % n

                if states[1] == 1:
                    tape[heads[1]] = (vals[1] & vals[0]) | (~vals[2] & 1)
                    states[1] = 2
                else:
                    tape[heads[1]] ^= vals[0]
                    states[1] = 1
                heads[1] = (heads[1] - 1) % n

                if states[2] == 2:
                    tape[heads[2]] = vals[0] ^ vals[1] ^ vals[2]
                    states[2] = 0
                else:
                    tape[heads[2]] = (vals[2] & vals[1]) | (~vals[0] & 1)
                    states[2] = 2
                heads[2] = (heads[2] + 2) % n

                mem.append(tuple(tape))

            # Checagem de consistÃªncia entre padrÃµes simbÃ³licos histÃ³ricos
            for i in range(1, len(mem)//3):
                past = mem[i]
                future = mem[-i-1][::-1]
                if past != future:
                    consistent_history = False
                    break

            acc = 1 if consistent_history else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl58 = level58_consciencia_simbolica_temporal(X)

    def level59_meta_inverse_conditional_transitivity(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as que se deslocam de forma reversÃ­vel e condicional
            h1, h2, h3 = 0, n // 3, 2 * n // 3
            s1, s2, s3 = 1, 0, 2

            transitions = []

            for _ in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # Regras com inversÃ£o condicional e simetria transitiva
                if s1 == 1:
                    tape[h1] = v2 ^ v3
                    s1 = 0
                else:
                    tape[h1] = (v1 & ~v2 & 1) | v3
                    s1 = 1
                h1 = (h1 + 1) % n

                if s2 == 0:
                    tape[h2] = (v2 | v3) ^ v1
                    s2 = 2
                else:
                    tape[h2] = (~v1 & 1) ^ (v2 & v3)
                    s2 = 0
                h2 = (h2 - 1) % n

                if s3 == 2:
                    tape[h3] = v1 ^ v2 ^ v3
                    s3 = 1
                else:
                    tape[h3] = (v1 & v2) | (v3 ^ 1)
                    s3 = 2
                h3 = (h3 + 2) % n

                # Armazena a transformaÃ§Ã£o para testar transitividade reversa
                transitions.append(tuple(tape))

            # VerificaÃ§Ã£o: cada transiÃ§Ã£o deve ser reversÃ­vel por pares espelhados
            reversible = True
            for i in range(1, len(transitions) // 2):
                if transitions[i] != transitions[-i - 1][::-1]:
                    reversible = False
                    break

            acc = 1 if reversible else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl59 = level59_meta_inverse_conditional_transitivity(X)

    def level60_mirror_machine_perturb(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as espelhadas
            h1, h2 = 0, n - 1
            state = 0
            perturb = 1

            history = []

            for _ in range(n):
                v1, v2 = tape[h1], tape[h2]

                if state == 0:
                    tape[h1] ^= (v2 ^ perturb)
                    tape[h2] ^= (v1 & perturb)
                    state = 1
                else:
                    tape[h1] = (v1 | perturb) ^ v2
                    tape[h2] = (v2 & ~perturb & 1) | v1
                    state = 0

                history.append(tuple(tape))
                h1 = (h1 + 1) % n
                h2 = (h2 - 1) % n

                # alterna perturbaÃ§Ã£o de forma controlada
                perturb = (perturb + 1) % 2

            # CondiÃ§Ã£o: reverso espelhado com tolerÃ¢ncia simÃ©trica
            passed = True
            for i in range(n // 2):
                left = history[i]
                right = history[-i - 1][::-1]
                diffs = sum(l != r for l, r in zip(left, right))
                if diffs > 1:  # tolerÃ¢ncia simbÃ³lica
                    passed = False
                    break

            acc = 1 if passed else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl60 = level60_mirror_machine_perturb(X)

    def level61_parallel_temporal_clocks(X):
        outputs = []
        for seq in X:
            n = len(seq)
            cycle_lengths = [4, 6, 9]
            clocks = [0, 0, 0]
            positions = [0, 0, 0]
            tapes = [[0]*length for length in cycle_lengths]

            for t, bit in enumerate(seq):
                for i in range(3):
                    pos = positions[i] % cycle_lengths[i]
                    if bit == 1:
                        tapes[i][pos] ^= 1
                    else:
                        tapes[i][pos] = (tapes[i][pos] + 1) % 2
                    positions[i] += 1

            final_states = [sum(tape) % 2 for tape in tapes]
            output = 1.0 if final_states.count(final_states[0]) == 3 else 0.0
            outputs.append(output)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl61 = level61_parallel_temporal_clocks(X)

    def level62_temporal_scramble_restore(X):
        outputs = []

        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Etapa 1: Embaralhamento temporal condicional reversÃ­vel
            scrambled = tape.copy()
            for i in range(1, n - 1, 2):
                scrambled[i], scrambled[i + 1] = scrambled[i + 1], scrambled[i]

            # Etapa 2: ReconstruÃ§Ã£o reversa condicional com regra de paridade simÃ©trica
            reconstructed = scrambled.copy()
            for i in range(n):
                if i % 3 == 0:
                    reconstructed[i] = scrambled[i] ^ scrambled[(i + 1) % n]
                elif i % 3 == 1:
                    reconstructed[i] = scrambled[i - 1] ^ scrambled[i]
                else:
                    reconstructed[i] = scrambled[i] ^ scrambled[(i - 2) % n]

            # Etapa 3: VerificaÃ§Ã£o â€“ o modelo deve inferir se a reconstruÃ§Ã£o equivale ao original
            is_correct = int(reconstructed == tape)
            outputs.append(is_correct)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl62 = level62_temporal_scramble_restore(X)

    # ğŸ§  NÃ­vel 63 â€“ ConsistÃªncia Temporal ContraditÃ³ria com Meta-ReversÃ£o

    def level63_contradictory_temporal_logic(X):
        outputs = []

        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # TrÃªs cabeÃ§as com estados
            h1, h2, h3 = 0, n // 3, (2 * n) // 3
            s1, s2, s3 = 0, 1, 2

            # HistÃ³rico de reversÃµes simuladas
            history = []

            for i in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # ReversÃ£o simulada com contradiÃ§Ã£o lÃ³gica:
                if s1 == 0:
                    tape[h1] = v2 ^ (~v3 & 1)
                    s1 = 1
                else:
                    tape[h1] = (v1 | v3) & v2
                    s1 = 0
                h1 = (h1 + 1) % n

                if s2 == 1:
                    tape[h2] ^= (v1 & v3)
                    s2 = 2
                else:
                    tape[h2] = (~v2 & 1) ^ v3
                    s2 = 1
                h2 = (h2 + 2) % n

                if s3 == 2:
                    tape[h3] = (v1 ^ v2 ^ v3)
                    s3 = 0
                else:
                    tape[h3] = ((v1 & v2) | (~v3 & 1))
                    s3 = 2
                h3 = (h3 - 1) % n

                history.append(tuple(tape))

            # VerificaÃ§Ã£o de consistÃªncia reversa lÃ³gica:
            consistent = True
            for i in range(n // 2):
                left = history[i]
                right = history[-i-1]
                contradiction = sum(a ^ b for a, b in zip(
                    left, right[::-1])) > n // 4
                if contradiction:
                    consistent = False
                    break

            acc = 1 if consistent else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl63 = level63_contradictory_temporal_logic(X)

    def level64_causal_mirror_loop(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as com deslocamentos cruzados
            h1, h2, h3 = 0, n//3, 2*n//3
            s1, s2, s3 = 0, 1, 2
            loop_check = []

            for i in range(n):
                v1, v2, v3 = tape[h1], tape[h2], tape[h3]

                # AtualizaÃ§Ãµes com reversÃ£o simbÃ³lica alternada
                if s1 == 0:
                    tape[h1] = (v2 ^ v3) & (~v1 & 1)
                    s1 = 1
                else:
                    tape[h1] ^= (v2 | v1)
                    s1 = 0
                h1 = (h1 + 1) % n

                if s2 == 1:
                    tape[h2] = (~v3 & 1) ^ (v1 & v2)
                    s2 = 2
                else:
                    tape[h2] = v1 ^ v2 ^ v3
                    s2 = 1
                h2 = (h2 + 2) % n

                if s3 == 2:
                    tape[h3] ^= v1 | (~v2 & 1)
                    s3 = 0
                else:
                    tape[h3] = (v3 & v1) ^ v2
                    s3 = 2
                h3 = (h3 - 1) % n

                # Salva estado parcial para verificar se o loop volta ao espelho
                loop_check.append(tuple(tape))

            # CorreÃ§Ã£o de loop: a primeira metade deve ser espelho da segunda
            valid = True
            for i in range(n // 2):
                if loop_check[i] != loop_check[-i-1][::-1]:
                    valid = False
                    break

            acc = 1 if valid else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl64 = level64_causal_mirror_loop(X)

    def level65_triptych_interpreter(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Divide em trÃªs partes: inÃ­cio, meio e fim
            third = n // 3
            start = tape[:third]
            middle = tape[third:2*third]
            end = tape[2*third:]

            # Fases com significados simbÃ³licos:
            # Start: intenÃ§Ã£o, Middle: conflito, End: resoluÃ§Ã£o

            # Interpreta a intenÃ§Ã£o
            intent = sum(start) % 2  # 0: estÃ¡vel, 1: desejando mudanÃ§a

            # Interpreta o conflito como soma dos XORs dos pares do meio
            conflict = 0
            for i in range(0, len(middle)-1, 2):
                conflict ^= middle[i] ^ middle[i+1]

            # Interpreta a resoluÃ§Ã£o como um delta de consistÃªncia
            resolution = 1 if sum(end) % 2 == conflict else 0

            # A lÃ³gica da mÃ¡quina: se intenÃ§Ã£o e resoluÃ§Ã£o batem, aceita
            result = 1 if resolution == intent else 0

            outputs.append(result)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl65 = level65_triptych_interpreter(X)

    y_lvl66 = None

    def level67_meta_cognition_symbolic(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            internal_state = [0] * n
            audit_log = []

            # CabeÃ§as simbÃ³licas que escrevem julgamentos internos
            h1, h2 = 0, n // 2
            s1, s2 = 0, 1

            for _ in range(n):
                v1, v2 = tape[h1], tape[h2]

                # Regra simbÃ³lica que aplica inferÃªncia e memorizaÃ§Ã£o interna
                if s1 % 2 == 0:
                    inferred = (v1 ^ v2) & 1
                else:
                    inferred = (~(v1 & v2)) & 1
                internal_state[h1] = inferred
                s1 += 1
                h1 = (h1 + 1) % n

                # CabeÃ§a 2 avalia a consistÃªncia da lÃ³gica gravada
                if s2 % 3 == 0:
                    audit = internal_state[h2] ^ tape[h2]
                else:
                    audit = ((internal_state[h2] & v1) | (~v2 & 1)) & 1
                audit_log.append(audit)
                s2 += 1
                h2 = (h2 - 1) % n

            # CondiÃ§Ã£o de metacogniÃ§Ã£o: se a sequÃªncia de auditorias Ã© palindrÃ´mica
            valid = all(audit_log[i] == audit_log[-i-1]
                        for i in range(len(audit_log)//2))
            acc = 1 if valid else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl67 = level67_meta_cognition_symbolic(X)

    # Meta-ConsistÃªncia Temporal com Espelhamento Consciente e Desvio Recursivo Adaptativo

    def level68_mirror_recursive_awareness(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as com deslocamentos simÃ©tricos e desvio adaptativo
            h1, h2 = 0, n - 1
            state = 0
            reflection_memory = []

            for i in range(n):
                v1, v2 = tape[h1], tape[h2]

                # Camada de raciocÃ­nio condicional reflexivo
                if state == 0:
                    op = (v1 & ~v2) ^ (v2 | v1)
                    tape[h1] = op
                    reflection_memory.append(op)
                    state = 1
                elif state == 1:
                    mirror_val = reflection_memory[-1] if reflection_memory else 0
                    op = (v2 ^ mirror_val) & (~v1 | 1)
                    tape[h2] = op
                    reflection_memory.append(op)
                    state = 2
                else:
                    feedback = sum(reflection_memory[-3:]) % 2
                    tape[h1] ^= feedback
                    tape[h2] ^= (~feedback & 1)
                    state = 0

                h1 = (h1 + 1) % n
                h2 = (h2 - 1) % n

            # CritÃ©rio de autoavaliaÃ§Ã£o metacognitiva
            segments = [tape[:n//3], tape[n//3:2*n//3], tape[2*n//3:]]
            consistency = all(seg == seg[::-1] for seg in segments)
            outputs.append(1 if consistency else 0)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl68 = level68_mirror_recursive_awareness(X)

    def level69_counterfactual_reversibility(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            history = []

            # Primeira simulaÃ§Ã£o com lÃ³gica causal reversÃ­vel
            for i in range(n):
                a = tape[i]
                b = tape[(i + 1) % n]
                c = tape[(i + 2) % n]

                out = (a ^ b) & (~c & 1)
                tape[i] = out
                history.append(list(tape))

            # RestauraÃ§Ã£o reversÃ­vel (tentativa contrafactual)
            reversed_pass = True
            tape_rev = history[-1].copy()

            for i in range(n - 1, -1, -1):
                a = tape_rev[i]
                b = tape_rev[(i - 1) % n]
                c = tape_rev[(i - 2) % n]

                rev = (a ^ c) | b
                if rev != X[0][i]:  # Esperado original
                    reversed_pass = False
                    break

            acc = 1 if reversed_pass else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl69 = level69_counterfactual_reversibility(X)

    def level70_temporal_contradiction_ambiguous(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # CabeÃ§as com direÃ§Ãµes reversÃ­veis e estados ambÃ­guos
            h1, h2 = 0, n - 1
            s1, s2 = 0, 1  # Estados internos das cabeÃ§as

            contradiction_detected = False
            memory_trace = []

            for t in range(n):
                v1, v2 = tape[h1], tape[h2]

                # Primeira cabeÃ§a: alterna entre propagar e inverter
                if s1 == 0:
                    tape[h1] ^= v2
                    s1 = 1
                else:
                    tape[h1] = (~v1 & 1)
                    s1 = 0
                h1 = (h1 + 1) % n

                # Segunda cabeÃ§a: armazena inconsistÃªncias temporais
                if s2 == 1:
                    result = (v1 & v2) ^ (t % 2)
                    tape[h2] = result
                    memory_trace.append(result)
                    if len(memory_trace) >= 4 and memory_trace[-1] == memory_trace[-3]:
                        contradiction_detected = True
                    s2 = 2
                else:
                    tape[h2] ^= (v1 | (~v2 & 1))
                    s2 = 1
                h2 = (h2 - 1) % n

            # Avalia se houve contradiÃ§Ã£o temporÃ¡ria reversÃ­vel
            paradox = (tape[0] ^ tape[-1]) and contradiction_detected
            acc = 1 if paradox else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl70 = level70_temporal_contradiction_ambiguous(X)

    def level71_recursive_symbolic_contradiction(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            contradiction_detected = False
            state = 0

            for i in range(n):
                a = tape[i]
                b = tape[(i + 1) % n]
                c = tape[(i + 2) % n]

                if state == 0:
                    if a == b:
                        state = 1
                    else:
                        state = 2

                elif state == 1:
                    if c == 1:
                        state = 3
                    else:
                        contradiction_detected = True
                        break

                elif state == 2:
                    if c == 0:
                        state = 4
                    else:
                        contradiction_detected = True
                        break

                elif state == 3:
                    if a ^ b ^ c == 1:
                        state = 0
                    else:
                        contradiction_detected = True
                        break

                elif state == 4:
                    if (a & b & c) == 0:
                        state = 0
                    else:
                        contradiction_detected = True
                        break

            outputs.append(1 if not contradiction_detected else 0)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # AplicaÃ§Ã£o:
    y_lvl71 = level71_recursive_symbolic_contradiction(X)

    def level72_hierarchical_auto_paradox(X):
        """
        NÃ­vel 72: RaciocÃ­nio simbÃ³lico hierÃ¡rquico com paradoxo temporal auto-referente.

        - Possui 2 nÃ­veis de atualizaÃ§Ã£o: 
        1) atualiza os bits da sequÃªncia com base em regras simbÃ³licas temporais, 
        2) verifica se a atualizaÃ§Ã£o gera um paradoxo com a memÃ³ria hierÃ¡rquica.
        - O resultado final (1 ou 0) depende de detectarmos ou nÃ£o um "loop paradoxal" auto-referente.
        """
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Duas "camadas" de atualizaÃ§Ã£o
            # Camada 1: inverte bits condicionalmente com base em tripletos
            # Camada 2: avalia contradiÃ§Ãµes hierÃ¡rquicas e registra paradoxos no "tape" tambÃ©m

            # MemÃ³ria hierÃ¡rquica para cada posiÃ§Ã£o (para paradoxos)
            hierarchy_mem = [0]*n

            paradox_detected = False

            # Primeira varredura (camada 1)
            for i in range(n):
                a = tape[i]
                b = tape[(i + 1) % n]
                c = tape[(i + 2) % n]
                if (a ^ b ^ c) == 1:
                    tape[i] ^= 1  # inverte
                else:
                    tape[i] = (tape[i] + 1) % 2  # incrementa mod 2

            # Segunda varredura (camada 2)
            for i in range(n):
                # Avalia possÃ­veis paradoxos entre tape[i], tape[i-1], hierarchy_mem[i]
                prev_idx = (i - 1) % n
                v = tape[i]
                vp = tape[prev_idx]
                h = hierarchy_mem[i]

                # Regras para atualizar hierarchy_mem
                if (v & vp) == 1:
                    hierarchy_mem[i] ^= 1
                elif (v | vp) == 0:
                    hierarchy_mem[i] = (h + 1) % 2
                else:
                    # Se h == v, surge uma contradiÃ§Ã£o hierÃ¡rquica
                    if h == v:
                        paradox_detected = True
                        break

            acc = 0 if paradox_detected else 1
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl72 = level72_hierarchical_auto_paradox(X)

    # ğŸ§  NÃ­vel 73 â€“ Polymorphic Substitution with Shifting States

    def level73_polymorphic_substitution(X):
        """
        NÃ­vel 73:
        - A cada iteraÃ§Ã£o, escolhe uma "regra polimÃ³rfica" (ex: xor, and, or, not)
        com base em um Ã­ndice rotativo que muda a cada passo.
        - Aplica no tape e rotaciona a tabela de substituiÃ§Ã£o a cada 2 passos.
        - Checa a consistÃªncia final: se a soma do tape (mod 2) 
        coincide com a soma dos Ã­ndices de regra usados.
        """
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)
            # Quatro regras polimÃ³rficas
            def rule0(a, b): return a ^ b
            def rule1(a, b): return (a & b)
            def rule2(a, b): return (a | (~b & 1))
            def rule3(a, b): return (~(a ^ b)) & 1

            rules = [rule0, rule1, rule2, rule3]
            rule_index = 0
            rule_sum = 0

            for i in range(n):
                a = tape[i]
                b = tape[(i+1) % n]

                # Aplica a regra polimÃ³rfica atual
                res = rules[rule_index](a, b)
                tape[i] = res

                rule_sum += rule_index
                # Rotaciona a tabela a cada 2 passos
                if i % 2 == 0:
                    rule_index = (rule_index + 1) % len(rules)

            # CritÃ©rio de consistÃªncia final
            final_sum = sum(tape) % 2
            check = rule_sum % 2
            outputs.append(1 if final_sum == check else 0)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl73 = level73_polymorphic_substitution(X)

    def level74_temporal_reflexive_symbolic(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            belief_state = [0] * n
            inconsistencies = 0

            # Passo 1: AvaliaÃ§Ã£o inicial de padrÃµes internos
            for i in range(n):
                a, b = tape[i], tape[(i+1) % n]
                belief_state[i] = (a ^ b) & 1

            # Passo 2: ReflexÃ£o simbÃ³lica cruzando o tempo
            for t in range(1, n):
                current = belief_state[t]
                past = belief_state[t - 1]
                future = belief_state[(t + 1) % n]

                # Simula reflexividade temporal: ajusta crenÃ§as se inconsistente
                expected = (past & future) | (~current & 1)
                if expected != current:
                    inconsistencies += 1
                    belief_state[t] = expected  # Corrige crenÃ§a

            # Resultado: se apÃ³s reflexÃ£o nÃ£o hÃ¡ inconsistÃªncia, Ã© 1
            acc = 1 if inconsistencies == 0 else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl74 = level74_temporal_reflexive_symbolic(X)

    def level75_dual_reversal_state_shift(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            state_forward = [0] * n
            state_backward = [0] * n

            # Etapa 1: Paridade reversa com reflexo Ã  frente
            for i in range(n):
                left = tape[i]
                right = tape[(i + 1) % n]
                # XOR com negaÃ§Ã£o invertida
                state_forward[i] = (left ^ ~right) & 1

            # Etapa 2: Paridade reversa espelhada para trÃ¡s
            for i in reversed(range(n)):
                a = tape[i]
                b = tape[(i - 1) % n]
                state_backward[i] = (~a ^ b) & 1

            # Etapa 3: AtualizaÃ§Ã£o assimÃ©trica cruzada entre estados
            final_state = []
            for i in range(n):
                s1 = state_forward[i]
                s2 = state_backward[(i + 2) % n]
                update = (s1 & s2) | ((~s1 | s2) & 1)
                final_state.append(update)

            # Etapa 4: ValidaÃ§Ã£o: sequÃªncia final deve ser palÃ­ndromo perfeito
            valid = final_state == final_state[::-1]
            outputs.append(1.0 if valid else 0.0)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Aplicar nos dados
    y_lvl75 = level75_dual_reversal_state_shift(X)

    def level76_meta_rule_hierarchical(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Passo 1: ConstruÃ§Ã£o de regras locais simbÃ³licas
            local_rules = []
            for i in range(1, n - 1):
                a, b, c = tape[i - 1], tape[i], tape[i + 1]
                rule = (a ^ b ^ c) & 1
                local_rules.append(rule)

            # Passo 2: FormaÃ§Ã£o da metarregra global
            # Exemplo: a maioria das regras locais define uma expectativa
            rule_sum = sum(local_rules)
            meta_rule = 1 if rule_sum > (len(local_rules) / 2) else 0

            # Passo 3: VerificaÃ§Ã£o de consistÃªncia hierÃ¡rquica
            inconsistencies = 0
            for i, rule in enumerate(local_rules):
                if rule != meta_rule:
                    inconsistencies += 1

            # Se houver muitas inconsistÃªncias, considera falha simbÃ³lica
            if inconsistencies > len(local_rules) * 0.25:
                outputs.append(0)
            else:
                outputs.append(1)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl76 = level76_meta_rule_hierarchical(X)

    # 15a5fe94ef6b226b4b6ef8c373c0724481e59243e4bb4940b2221ddc8d149ba7 lvl 77 Hash

    def level77_reflexive_symbolic_quantum_mirroring(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            inner_state = [0] * n
            conflict = 0

            # Etapa 1: ReflexÃ£o SimbÃ³lica Espelhada
            for i in range(n):
                mirrored = tape[n - 1 - i]
                inner_state[i] = (tape[i] ^ mirrored) & 1

            # Etapa 2: SimulaÃ§Ã£o de Colapso de Estado
            for t in range(n):
                past = inner_state[t - 1] if t > 0 else 0
                now = inner_state[t]
                future = inner_state[t + 1] if t < n - 1 else 0

                collapse = (past & future) ^ now
                if collapse != 0:
                    conflict += 1

            acc = 1 if conflict == 0 else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Uso no pipeline
    y_lvl77 = level77_reflexive_symbolic_quantum_mirroring(X)

    # Hash de controle para integridade
    hash_77 = hashlib.sha256(y_lvl77.tobytes()).hexdigest()
    print("SHA-256 Level 77:", hash_77)

    # level 78 - inferÃªncia causal reversa com consistÃªncia simbÃ³lica de tempo

    def level78_temporal_causal_inference(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            belief = [0] * n
            inconsistencies = 0

            # Passo 1: GeraÃ§Ã£o inicial de crenÃ§as causais (XOR entre presente e passado)
            for t in range(n):
                past = tape[t - 1]
                present = tape[t]
                belief[t] = past ^ present  # relaÃ§Ã£o causal inicial

            # Passo 2: SimulaÃ§Ã£o de previsÃ£o causal (presente => futuro esperado)
            for t in range(n - 1):
                future_expected = tape[t] ^ belief[t]
                if future_expected != tape[t + 1]:
                    inconsistencies += 1
                    # Corrige crenÃ§a simbÃ³lica com inferÃªncia reversa
                    belief[t] = tape[t] ^ tape[t + 1]

            # Passo 3: ValidaÃ§Ã£o de consistÃªncia cruzada
            consistent = True
            for t in range(n - 2):
                fwd = belief[t]
                rev = tape[t] ^ tape[t + 1]
                if fwd != rev:
                    consistent = False
                    break

            outputs.append(1.0 if consistent and inconsistencies == 0 else 0.0)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Aplicando o nÃ­vel
    y_lvl78 = level78_temporal_causal_inference(X)

    # lvl 79 - IA simbÃ³lica auto-reflexiva

    def level79_auto_critical_symbolic_loop(X):
        outputs = []
        for seq in X:
            n = len(seq)
            symbolic_belief = [0] * n
            critical_belief = [0] * n
            inconsistencies = 0

            # Primeira camada: inferÃªncia simbÃ³lica local (regra bÃ¡sica: XOR entre vizinhos)
            for i in range(n):
                a, b = seq[i], seq[(i + 1) % n]
                symbolic_belief[i] = a ^ b

            # Segunda camada: auto-crÃ­tica baseada em padrÃµes globais (se padrÃ£o repetir, negar)
            for i in range(1, n - 1):
                window = symbolic_belief[i - 1:i + 2]
                if window.count(window[1]) == 3:
                    # padrÃ£o constante â†’ suspeita de ilusÃ£o simbÃ³lica â†’ negar crenÃ§a
                    critical_belief[i] = int(not symbolic_belief[i])
                else:
                    # padrÃ£o variado â†’ reforÃ§a crenÃ§a
                    critical_belief[i] = symbolic_belief[i]

            # ValidaÃ§Ã£o: inconsistÃªncia se as duas camadas forem diferentes em muitos pontos
            diff = sum(
                [1 for i in range(n) if symbolic_belief[i] != critical_belief[i]])
            if diff > n * 0.3:  # mais de 30% de conflito interno
                outputs.append(0.0)
            else:
                outputs.append(1.0)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Para gerar os rÃ³tulos:
    y_lvl79 = level79_auto_critical_symbolic_loop(X)

    # lvl 80 reflexÃ£o simbÃ³lica adaptativa com cruzamento temporal

    def level80_meta_symbolic_adaptive_reflection(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            symbol_memory = [0] * n
            feedback_loop = [0] * n
            anomaly_count = 0

            # Fase 1: ConstruÃ§Ã£o de sÃ­mbolos temporais baseados em XOR de pares cruzados
            for i in range(n):
                a = tape[i]
                b = tape[(i + 2) % n]
                symbol_memory[i] = (a ^ b) & 1

            # Fase 2: ReflexÃ£o adaptativa com dependÃªncia simbÃ³lica invertida
            for i in range(n):
                prev = symbol_memory[i - 1]
                next_ = symbol_memory[(i + 1) % n]
                decision = (prev & next_) | ((~prev & 1) & (~next_ & 1))

                # Cria ciclo de feedback simbÃ³lico
                feedback_loop[i] = decision ^ symbol_memory[i]

            # Fase 3: AvaliaÃ§Ã£o da consistÃªncia simbÃ³lica cruzada com auto-revisÃ£o
            for i in range(n):
                mirrored = feedback_loop[n - 1 - i]
                if mirrored != symbol_memory[i]:
                    anomaly_count += 1

            result = 1 if anomaly_count == 0 else 0
            outputs.append(result)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # Exemplo de uso:
    y_lvl80 = level80_meta_symbolic_adaptive_reflection(X)

    # lvl 81 - meta-representaÃ§Ã£o simbÃ³lica nÃ£o supervisionada - razao simbolica autonoma

    def level81_meta_repr_unsupervised(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            contradictions = 0

            # Janela de 4 elementos com anÃ¡lise causal invertida
            for i in range(n - 3):
                a, b, c, d = tape[i], tape[i+1], tape[i+2], tape[i+3]

                # Suposta causa: a XOR b
                cause = a ^ b
                # Suposto efeito esperado: c AND d
                effect = c & d

                # Meta-representaÃ§Ã£o invertida (efeito deveria implicar causa)
                if (effect and not cause) or (not effect and cause):
                    contradictions += 1

            # Se nÃºmero de contradiÃ§Ãµes for Ã­mpar, colapso da coerÃªncia interna
            acc = 0 if contradictions % 2 == 1 else 1
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl81 = level81_meta_repr_unsupervised(X)

    # lvl 82 ğŸ§ âš–ï¸ NÃ­vel 82: DialÃ©tica Temporal SimbÃ³lica

    def level82_dialectic_temporal(X):
        outputs = []
        for seq in X:
            n = len(seq)
            state = 0
            dialectic = 0
            for i in range(n):
                a = seq[i]
                b = seq[(i + 1) % n]
                if state == 0:
                    dialectic ^= a & (~b & 1)
                    state = 1
                else:
                    dialectic ^= b | a
                    state = 0
            acc = dialectic % 2
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl82 = level82_dialectic_temporal(X)

    # ğŸ”ğŸŒ€ NÃ­vel 83: InferÃªncia Abdutiva Reversa

    def level83_abductive_reverse_inference(X):
        outputs = []
        for seq in X:
            hypothesis = 1
            for i in reversed(range(len(seq))):
                a = seq[i]
                if i % 2 == 0:
                    hypothesis ^= a
                else:
                    hypothesis &= a
            acc = hypothesis
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl83 = level83_abductive_reverse_inference(X)

    # â³ğŸ§  NÃ­vel 84: Paradoxo Temporal Simulado

    def level84_paradox_temporal(X):
        outputs = []
        for seq in X:
            n = len(seq)
            paradox = False
            for i in range(1, n - 1):
                past = seq[i - 1]
                current = seq[i]
                future = seq[i + 1]
                if (past ^ future) == current:
                    paradox = not paradox
            acc = 1 if paradox else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl84 = level84_paradox_temporal(X)

    # ğŸ§ ğŸ”¬ NÃ­vel 85: MetaavaliaÃ§Ã£o de ConfianÃ§a Temporal

    def level85_meta_confidence(X):
        outputs = []
        for seq in X:
            n = len(seq)
            confidence = 0
            for i in range(n):
                bit = seq[i]
                prior = seq[i - 1] if i > 0 else 0
                next_ = seq[(i + 1) % n]
                belief = (bit & prior) | (~bit & 1 & next_)
                confidence += belief
            acc = 1 if (confidence % 2 == 1) else 0
            outputs.append(acc)
        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl85 = level85_meta_confidence(X)

    def level86_proto_agente_temporal(X):
        outputs = []
        for seq in X:
            tape = list(seq.copy())
            n = len(tape)

            # Supomos que hÃ¡ um "agente" se movendo simbolicamente
            # baseado na sequÃªncia de bits, onde 1 representa movimento e 0 pausa
            position = 0
            goal = n // 2  # objetivo implÃ­cito Ã© atingir o centro
            reached_goal = False

            for t in range(n):
                action = tape[t]
                # Movimento simbÃ³lico (agente imaginÃ¡rio avanÃ§a se aÃ§Ã£o == 1)
                if action == 1:
                    position += 1
                else:
                    position -= 1  # retrocede se pausa longa demais

                # Se em algum momento chegou ao "objetivo"
                if abs(position - goal) <= 1:
                    reached_goal = True

            # Sucesso simbÃ³lico se agente alcanÃ§ou regiÃ£o do objetivo
            acc = 1 if reached_goal else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl86 = level86_proto_agente_temporal(X)

    def level87_symbolic_persistent_agency(X):
        outputs = []
        for seq in X:
            n = len(seq)
            # Etapa 1: Detecta centro de intenÃ§Ã£o (posiÃ§Ã£o ideal)
            ideal_pos = n // 2

            # Etapa 2: Analisa a trajetÃ³ria simbÃ³lica atÃ© o centro
            path = []
            for i in range(n):
                # simboliza direÃ§Ã£o de movimento
                move = 1 if seq[i] > 0.5 else -1
                path.append(move)

            # Etapa 3: Simula persistÃªncia e checa reversÃµes de intenÃ§Ã£o
            intention = None
            consistency = True
            for move in path:
                if intention is None:
                    intention = move
                elif move != intention:
                    consistency = False
                    break

            # Etapa 4: Confere se o movimento foi na direÃ§Ã£o do centro
            net_movement = sum(path)
            reached_center = (intention == 1 and net_movement >= 0) or \
                (intention == -1 and net_movement <= 0)

            # SaÃ­da simbÃ³lica: 1 se seguiu rumo consistente ao centro, 0 caso contrÃ¡rio
            result = 1 if consistency and reached_center else 0
            outputs.append(result)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    # AplicaÃ§Ã£o
    y_lvl87 = level87_symbolic_persistent_agency(X)

    #  NÃ­vel 88: Ontologia Temporo-Causal Consensual

    def level88_temporal_causal_ontology(X):
        outputs = []
        for seq in X:
            n = len(seq)
            agents = 3
            memory = [[0]*n for _ in range(agents)]

            # Cada agente observa um deslocamento diferente da realidade
            for a in range(agents):
                offset = a  # visÃµes temporais deslocadas
                for i in range(n):
                    memory[a][i] = seq[(i + offset) % n] ^ ((i + a) % 2)

            # Consenso ontolÃ³gico: todos devem convergir para mesma versÃ£o
            consensus = []
            for i in range(n):
                values = [memory[a][i] for a in range(agents)]
                consensus.append(
                    1 if all(v == values[0] for v in values) else 0)

            acc = 1 if all(x == 1 for x in consensus) else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl88 = level88_temporal_causal_ontology(X)

    #  NÃ­vel 89: SimulaÃ§Ã£o de Realidade Subjetiva

    def level89_subjective_reality_simulation(X):
        outputs = []
        for seq in X:
            n = len(seq)
            subjective = [0]*n
            objective = [0]*n

            # PercepÃ§Ãµes subjetivas (com ruÃ­do simbÃ³lico) e realidade objetiva
            for i in range(n):
                subjective[i] = seq[i] ^ ((i % 3) == 0)
                objective[i] = seq[i]

            # O agente precisa detectar os pontos em que a percepÃ§Ã£o diverge da realidade
            error_positions = [1 if subjective[i] !=
                               objective[i] else 0 for i in range(n)]

            # A saÃ­da Ã© 1 se o agente conseguir detectar exatamente todos os desvios
            acc = 1 if sum(error_positions) == n // 3 else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl89 = level89_subjective_reality_simulation(X)

    # NÃ­vel 90: Teste de Autoengano Temporal SimbÃ³lico

    def level90_temporal_self_deception(X):
        outputs = []
        for seq in X:
            n = len(seq)
            belief = [s for s in seq]
            memory = [0]*n
            inconsistencies = 0

            # Inicialmente assume crenÃ§as erradas (autoengano)
            for i in range(n):
                belief[i] = seq[i] ^ 1  # nega a verdade

            # ReflexÃ£o temporal para identificar autoengano
            for t in range(1, n - 1):
                past = belief[t - 1]
                current = belief[t]
                future = belief[t + 1]

                # Detecta contradiÃ§Ãµes entre presente e tempo ao redor
                expected = (past & future)
                if current != expected:
                    inconsistencies += 1
                    belief[t] = expected  # corrige a si mesmo

            acc = 1 if inconsistencies <= 1 else 0
            outputs.append(acc)

        return np.array(outputs).reshape(-1, 1).astype(np.float32)

    y_lvl90 = level90_temporal_self_deception(X)

    # NÃ­vel 91

    def level91_counterfactual_reflection(X):
        """
        Para cada amostra binÃ¡ria X[i], verifica se a paridade mudaria
        ao inverter os bits das posiÃ§Ãµes crÃ­ticas [1, 2, 4].
        Retorna 1 se alguma inversÃ£o mudar a paridade original.
        """
        X = np.array(X)
        original = np.sum(X, axis=1) % 2

        # Inverter posiÃ§Ãµes crÃ­ticas
        alt_realities = []
        for pos in [1, 2, 4]:
            X_flipped = X.copy()
            X_flipped[:, pos] = 1 - X_flipped[:, pos]
            parity_flipped = np.sum(X_flipped, axis=1) % 2
            alt_realities.append(parity_flipped)

        alt_realities = np.stack(alt_realities, axis=1)
        change_detected = np.any(
            alt_realities != original[:, np.newaxis], axis=1)
        return change_detected.astype(int)

    y_lvl91 = level91_counterfactual_reflection(X)

    # Nivel 92

    def level92_meta_interpretation(X):
        """
        Avalia se a decisÃ£o anterior embutida na sequÃªncia estÃ¡ correta e a corrige.

        Entrada: X de shape (batch_size, seq_len)
        Ãšltimo bit representa a 'resposta anterior'.
        """
        logical_part = X[:, :-1]
        previous_answer = X[:, -1]
        logical_inference = (
            np.sum(logical_part[:, ::2], axis=1) % 2 == 1).astype(int)
        return (previous_answer != logical_inference).astype(int)

    y_lvl92 = level92_meta_interpretation(X)

    # Nivel 93

    def level93_ethical_evaluation(X):
        """
        Julga a moralidade de uma aÃ§Ã£o com base em intenÃ§Ã£o, dano e benefÃ­cio.

        Entrada: X com shape (batch_size, 3)
        - X[:, 0] = intenÃ§Ã£o (0 ou 1)
        - X[:, 1] = dano (0 ou 1)
        - X[:, 2] = benefÃ­cio (0 ou 1)

        Retorna 1 se a aÃ§Ã£o Ã© eticamente aceitÃ¡vel, 0 caso contrÃ¡rio.
        """
        intencao = X[:, 0]
        dano = X[:, 1]
        beneficio = X[:, 2]

        return ((intencao == 1) & (dano == 0) & (beneficio == 1)).astype(int)

    y_lvl93 = level93_ethical_evaluation(X)

    # ğŸ§© NÃ­vel 94 â€“ ConsistÃªncia Ã‰tico-Temporal

    def level94_ethic_temporal_consistency(X):
        """
        Cada linha de X tem 6 elementos representando duas aÃ§Ãµes:
        [int1, dano1, ben1, int2, dano2, ben2]
        Retorna 1 se as duas aÃ§Ãµes forem moralmente vÃ¡lidas (intenÃ§Ã£o=1, dano=0, benefÃ­cio=1)
        """
        X = np.array(X)

        int1, dano1, ben1 = X[:, 0], X[:, 1], X[:, 2]
        int2, dano2, ben2 = X[:, 3], X[:, 4], X[:, 5]

        valid1 = (int1 == 1) & (dano1 == 0) & (ben1 == 1)
        valid2 = (int2 == 1) & (dano2 == 0) & (ben2 == 1)

        return (valid1 & valid2).astype(int)

    y_lvl94 = level94_ethic_temporal_consistency(X)

    # ğŸ§  NÃ­vel 95 â€“ Autojulgamento Moral

    def level95_self_moral_judgment(X):
        """
        O modelo deve julgar se sua prÃ³pria decisÃ£o anterior foi Ã©tica.
        Cada linha de X tem 4 elementos: [intencao, dano, beneficio, julgamento_prev]
        A saÃ­da Ã© 1 se o julgamento anterior for coerente com os princÃ­pios Ã©ticos.
        """
        X = np.array(X)
        intencao = X[:, 0]
        dano = X[:, 1]
        beneficio = X[:, 2]
        julgamento_prev = X[:, 3]

        # Julgamento ideal com base em princÃ­pios Ã©ticos
        julgamento_ideal = (intencao == 1) & (dano == 0) & (beneficio == 1)

        # A saÃ­da Ã© 1 se julgamento anterior bate com o ideal
        return (julgamento_prev == julgamento_ideal.astype(int)).astype(int)

    y_lvl95 = level95_self_moral_judgment(X)

    # ğŸŒ€ NÃ­vel 96 â€“ MetaÃ©tica SimbÃ³lica

    def level96_metaethical_reasoning(X):
        """
        Cada linha de X contÃ©m 9 valores representando 3 aÃ§Ãµes:
        [int1, dano1, ben1, int2, dano2, ben2, int3, dano3, ben3]

        O modelo deve escolher a aÃ§Ã£o com maior pontuaÃ§Ã£o moral,
        baseada em uma heurÃ­stica ponderada:
            - IntenÃ§Ã£o: peso +2 (quanto maior, melhor)
            - Dano: peso -3 (quanto menor, melhor)
            - BenefÃ­cio: peso +2 (quanto maior, melhor)
        """
        X = np.array(X)
        if X.shape[1] != 9:
            raise ValueError(
                f"Esperado X com 9 colunas, mas recebi shape {X.shape}")

        X = X.reshape(-1, 3, 3)  # (n_amostras, 3 aÃ§Ãµes, 3 critÃ©rios)

        # AtribuiÃ§Ã£o de pesos Ã©ticos
        peso_intencao = 2
        peso_dano = -3
        peso_beneficio = 2

        # Calcula a pontuaÃ§Ã£o Ã©tica para cada aÃ§Ã£o
        scores = (
            peso_intencao * X[:, :, 0] +
            peso_dano * X[:, :, 1] +
            peso_beneficio * X[:, :, 2]
        )

        # Escolhe a aÃ§Ã£o com maior score (0, 1 ou 2)
        return np.argmax(scores, axis=1)

    def gerar_dados(n_amostras, n_features, seed=None):
        """
        Gera exemplos com coerÃªncia moral controlada.
        """
        if seed is not None:
            np.random.seed(seed)

        dados = []
        for _ in range(n_amostras):
            aÃ§Ãµes = []
            for _ in range(3):  # 3 aÃ§Ãµes
                intencao = np.random.choice([0, 1, 2], p=[0.2, 0.4, 0.4])
                # mais propenso a ser Ã©tico
                dano = np.random.choice([0, 1, 2], p=[0.6, 0.3, 0.1])
                beneficio = np.random.choice([0, 1, 2], p=[0.2, 0.3, 0.5])
                aÃ§Ãµes.extend([intencao, dano, beneficio])
            dados.append(aÃ§Ãµes)
        return np.array(dados)

    X_lvl96 = gerar_dados(10000, 9)

    y_lvl96 = level96_metaethical_reasoning(X_lvl96)

    #

    y_sum = np.sum(X, axis=1).reshape(-1, 1).astype(np.float32)

    return X, y_lvl1, y_lvl2, y_lvl3, y_lvl4, y_lvl5, y_lvl6, y_lvl7, y_lvl8, y_lvl9, y_lvl10, y_lvl11, y_lvl12, y_lvl13, y_lvl14, y_lvl15, y_lvl16, y_lvl17, y_lvl18, y_lvl19, y_lvl20, y_lvl21, y_lvl22, y_lvl23, y_lvl24, y_lvl25, y_lvl26, y_lvl27, y_lvl28, y_lvl29, y_lvl30, y_lvl31, y_lvl32, y_lvl33, y_lvl34, y_lvl35, y_lvl36, y_lvl37, y_lvl38, y_lvl39, y_lvl40, y_lvl41, y_lvl42, y_lvl43, y_lvl44, y_lvl45, y_lvl46, y_lvl47, y_lvl48, y_lvl49, y_lvl50, y_lvl51, y_lvl52, y_lvl53, y_lvl54, y_lvl55, y_lvl56, y_lvl57, y_lvl58, y_lvl59, y_lvl60, y_lvl61,  y_lvl62, y_lvl63, y_lvl64,  y_lvl65, y_lvl66, y_lvl67,  y_lvl68, y_lvl69, y_lvl70, y_lvl71,  y_lvl72, y_lvl73, y_lvl74, y_lvl75, y_lvl76, y_lvl77, y_lvl78, y_lvl79, y_lvl80, y_lvl81, y_lvl82, y_lvl83, y_lvl84, y_lvl85, y_lvl86, y_lvl87, y_lvl88, y_lvl89, y_lvl90, y_lvl91, y_lvl92, y_lvl93, y_lvl94, y_lvl95, y_lvl96, y_sum


def structured_embedding(X, symbol_dim=6):
    np.random.seed(42)
    embed_0 = np.random.uniform(-1, 1, size=symbol_dim)
    embed_1 = -embed_0
    return np.array([[embed_0 if bit == 0 else embed_1 for bit in seq] for seq in X])


def build_model(model_type, input_shape):
    input_layer = Input(shape=input_shape, name="input")

    if model_type == 'Dense':
        x = Dense(6, activation='gelu', name='dense_1')(input_layer)
        x = Dense(96, activation='gelu', name='dense_2')(x)

    elif model_type == 'LSTM':
        x = LSTM(96, activation='tanh', return_sequences=False,
                 name='lstm')(input_layer)

    elif model_type == 'SAGE-1':
        x = SAGE_ONE()(input_layer)

    else:
        raise ValueError(f"Modelo desconhecido: {model_type}")

    out_parity = Dense(3, activation='softmax', kernel_initializer='he_uniform', name='parity')(
        x)  # Para classificaÃ§Ã£o em 3 classes
    out_sum = Dense(1, activation='linear', name='sum_odd')(
        x)     # Para regressÃ£o (opcional)

    model = Model(inputs=input_layer, outputs=out_parity, name=model_type)
    return model


def train_model(model, X_train, y_train_dict, X_test, y_test_dict):
    optimizer = tf.keras.optimizers.AdamW(
        learning_rate=5e-3,
        weight_decay=1e-4
    )

    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['sparse_categorical_accuracy']
    )

    try:
        start_time = time.time()

        # âœ… Balanceamento dos pesos da classe de paridade
        classes = np.unique(y_train_dict['parity'])
        weights = compute_class_weight(
            class_weight='balanced', classes=classes, y=y_train_dict['parity'])
        class_weight_dict = dict(zip(classes, weights))

        early_stop = EarlyStopping(
            monitor='val_loss',
            patience=25,
            restore_best_weights=True
        )

        # âœ… Treinamento com apenas a saÃ­da de paridade
        history = model.fit(
            X_train, y_train_dict['parity'],
            epochs=500,
            batch_size=32,
            validation_split=0.3,
            verbose=1,
            class_weight=class_weight_dict,
            callbacks=[early_stop]
        )

        elapsed_time = time.time() - start_time

        # âœ… AvaliaÃ§Ã£o
        eval_results = model.evaluate(X_test, y_test_dict['parity'], verbose=0)

        acc = None
        for name, val in zip(model.metrics_names, eval_results):
            if name in ['parity_accuracy', 'accuracy', 'sparse_categorical_accuracy']:
                acc = val
                break
        if acc is None and len(eval_results) > 0:
            acc = eval_results[-1]

        return acc, elapsed_time, history

    except Exception as e:
        print(f"âŒ Erro ao treinar o modelo {model.name}: {e}")
        return None, None, None


def run_benchmark(parity_level=1):
    X, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12, y13, y14, y15, y16, y17, y18, y19, y20, y21, y22, y23, y24, y25, y26, y27, y28, y29, y30, y31, y32, y33, y34, y35, y36, y37, y38, y39, y40, y41, y42, y43, y44, y45, y46, y47, y48, y49, y50, y51, y52, y53, y54, y55, y56, y57, y58, y59, y60, y61, y62, y63, y64, y65, y66, y67, y68, y69, y70, y71, y72, y73, y74, y75, y76, y77, y78, y79, y80, y81, y82, y83, y84, y85, y86, y87, y88, y89, y90, y91, y92, y93, y94, y95, y96, y_sum = generate_parity_levels()
    y_parity = {1: y1, 2: y2, 3: y3, 4: y4,
                5: y5, 6: y6, 7: y7, 8: y8,
                9: y9, 10: y10, 11: y11,
                12: y12, 13: y13, 14: y14,
                15: y15, 16: y16, 17: y17,
                18: y18, 19: y19, 20: y20,
                21: y21, 22: y22, 23: y23,
                24: y24, 25: y25, 26: y26,
                27: y27, 28: y28, 29: y29,
                30: y30, 31: y31, 32: y32,
                33: y33, 34: y34, 35: y35,
                36: y36, 37: y37, 38: y38,
                39: y39, 40: y40, 41: y41,
                42: y42, 43: y43, 44: y44,
                45: y45, 46: y46, 47: y47,
                48: y48, 49: y49, 50: y50,
                51: y51, 52: y52, 53: y53,
                54: y54, 55: y55, 56: y56,
                57: y57, 58: y58, 59: y59,
                60: y60, 61: y61, 62: y62,
                63: y63, 64: y64, 65: y65,
                66: y66, 67: y67, 68: y68,
                69: y69, 70: y70, 71: y71,
                72: y72, 73: y73, 74: y74,
                75: y75, 76: y76, 77: y77,
                78: y78, 79: y79, 80: y80,
                81: y81, 82: y82, 83: y83,
                84: y84, 85: y85, 86: y86,
                87: y87, 88: y88, 89: y89,
                90: y90, 91: y91, 92: y92,
                93: y93, 94: y94, 95: y95,
                96: y96, }[parity_level]

    # Converte para rÃ³tulo inteiro se for one-hot
    if len(y_parity.shape) > 1 and y_parity.shape[1] > 1:
        y_parity = np.argmax(y_parity, axis=1)

    X_train, X_test, y_train_p, y_test_p, y_train_s, y_test_s = train_test_split(
        X, y_parity, y_sum, test_size=0.2)

    X_train_emb = structured_embedding(X_train)
    X_test_emb = structured_embedding(X_test)

    input_shapes = {
        'Dense': (X_train_emb.shape[1] * X_train_emb.shape[2],),
        'LSTM': (X_train_emb.shape[1], X_train_emb.shape[2]),
        'SAGE-1': (X_train_emb.shape[1], X_train_emb.shape[2]),
    }

    results = {}
    histories = {}

    for model_type in ['Dense', 'LSTM', 'SAGE-1']:
        try:
            print(f"\nğŸš€ Treinando modelo: {model_type}")
            model = build_model(model_type, input_shapes[model_type])

            if model_type == 'Dense':
                X_train_, X_test_ = X_train_emb.reshape(
                    len(X_train_emb), -1), X_test_emb.reshape(len(X_test_emb), -1)
            else:
                X_train_, X_test_ = X_train_emb, X_test_emb

            # Garante que os rÃ³tulos estejam em formato inteiro (sparse), como esperado
            if len(y_train_p.shape) > 1 and y_train_p.shape[1] > 1:
                y_train_p = np.argmax(y_train_p, axis=1)
                y_test_p = np.argmax(y_test_p, axis=1)

            y_train_dict = {'parity': y_train_p, 'sum_odd': y_train_s}
            y_test_dict = {'parity': y_test_p, 'sum_odd': y_test_s}

            acc, time_spent, history = train_model(
                model, X_train_, y_train_dict, X_test_, y_test_dict)

            if acc is not None:
                results[model_type] = (acc, time_spent)
                histories[model_type] = history

        except Exception as e:
            print(f"âŒ Erro ao treinar o modelo {model_type}: {e}")
            continue

    print("\nğŸ“Š Modelos treinados:", list(results.keys()))
    return results, histories


def plot_results(results):
    if not results:
        print("âš ï¸ Nenhum resultado para plotar.")
        return
    df = pd.DataFrame(results, index=['Accuracy', 'Time']).T
    plt.figure(figsize=(10, 6))
    bars = plt.bar(df.index, df.Accuracy, color=[
                   '#1f77b4', '#2ca02c', '#d62728'])
    for bar, acc, time in zip(bars, df.Accuracy, df.Time):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()+0.01,
                 f'{acc:.3f}\n({time:.1f}s)', ha='center', va='bottom')
    plt.ylim(0.0, 1.05)
    plt.title('Comparacao de Modelos em Tarefa de Paridade')
    plt.ylabel('Acuracia')
    plt.show()


def plot_results_curves(histories):
    plt.figure(figsize=(12, 6))

    for model_name, history in histories.items():
        print(f"\nğŸ” {model_name} history keys: {list(history.history.keys())}")
        acc_keys = [k for k in history.history.keys(
        ) if 'accuracy' in k and not k.startswith('val_')]
        val_keys = [k for k in history.history.keys(
        ) if k.startswith('val') and 'accuracy' in k]

        if acc_keys:
            acc = history.history[acc_keys[0]]
            epochs = range(1, len(acc) + 1)
            plt.plot(epochs, acc, label=f'{model_name} - Treino')

        if val_keys:
            val_acc = history.history[val_keys[0]]
            epochs = range(1, len(val_acc) + 1)
            plt.plot(epochs, val_acc, linestyle='--',
                     label=f'{model_name} - ValidaÃ§Ã£o')

    plt.title('Curva de Acuracia por Epoca')
    plt.xlabel('Epoca')
    plt.ylabel('Acuracia')
    plt.ylim(0.0, 1.05)
    plt.legend()
    plt.grid(True)
    plt.show()


if __name__ == "__main__":
    results, histories = run_benchmark(parity_level=96)
    plot_results(results)
    plot_results_curves(histories)
